{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import json\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set up training and testing data\n",
    "root = 'D:/COCO Dataset'\n",
    "if not os.path.exists(root):\n",
    "    os.mkdir(root)\n",
    "\n",
    "train_dataset = datasets.CocoDetection(root + '/train2017',\n",
    "                                       'D:/COCO Dataset/annotations/instances_train2017.json',\n",
    "                                       transform=transforms.Compose([transforms.Resize((256, 256)),\n",
    "                                                                     transforms.ToTensor()]))\n",
    "\n",
    "test_dataset = datasets.CocoDetection(root + '/val2017',\n",
    "                                      'D:/COCO Dataset/annotations/instances_val2017.json',\n",
    "                                      transform=transforms.Compose([transforms.Resize((256, 256)),\n",
    "                                                                    transforms.ToTensor()]))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "# Define model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, 1, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=128)\n",
    "\n",
    "        # linear layers\n",
    "        self.fc1 = nn.Linear(128*32*32, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # convolutional layers with batch normalization\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(F.relu(self.bn2(self.conv2(x))), 2)\n",
    "        x = F.max_pool2d(F.relu(self.bn3(self.conv3(x))), 2)\n",
    "\n",
    "        # flatten to feed into linear layers\n",
    "        x = x.view(-1, 128*32*32)\n",
    "        # linear layers\n",
    "        x = F.dropout(F.relu(self.fc1(x)), 0.5)\n",
    "        x = F.dropout(F.relu(self.fc2(x)), 0.5)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train model\n",
    "def train(model, device, train_loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "# Test model\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "for epoch in range(1, 11):\n",
    "  train(model, device, train_loader, optimizer, criterion, epoch)\n",
    "  test(model, device, test_loader)\n",
    "\n",
    "# Detect Persons in an image\n",
    "def detect_person(model, img_path):\n",
    "    transform = transforms.Compose([transforms.Resize((256, 256)),\n",
    "                                    transforms.ToTensor()])\n",
    "    img = Image.open(img_path)\n",
    "    img = transform(img)\n",
    "    img = img.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(img[None, ...])\n",
    "        _, preds = torch.max(output, 1)\n",
    "    if preds.item() == 1:\n",
    "        print(\"Person detected!\")\n",
    "    else:\n",
    "        print(\"No person detected!\")\n",
    "\n",
    "# Test image\n",
    "img_url = 'https://www.wired.com/wp-content/uploads/2015/09/google-logo.jpg'\n",
    "response = requests.get(img_url)\n",
    "img = Image.open(BytesIO(response.content))\n",
    "img.save(\"test.jpg\")\n",
    "\n",
    "# Detect persons in the test image\n",
    "detect_person(model, 'test.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=17.55s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set up training and testing data\n",
    "root = 'D:/COCO Dataset'\n",
    "if not os.path.exists(root):\n",
    "    os.mkdir(root)\n",
    "\n",
    "class ResizeTransform:\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        \n",
    "    def __call__(self, img):\n",
    "        return transforms.functional.resize(img, self.size)\n",
    "\n",
    "train_dataset = datasets.CocoDetection(root + '/train2017',\n",
    "                                       'D:/COCO Dataset/annotations/instances_train2017.json',\n",
    "                                       transform=transforms.Compose([ResizeTransform((256, 256)),\n",
    "                                                                     transforms.ToTensor()]))\n",
    "\n",
    "\n",
    "# Define collate function that resizes images to the same size\n",
    "def collate_fn(batch):\n",
    "    images = []\n",
    "    targets = []\n",
    "    for image, target in batch:\n",
    "        # Resize image\n",
    "        image = ResizeTransform((256, 256))(image)\n",
    "        images.append(transforms.ToTensor()(image))\n",
    "        targets.append(target)\n",
    "    return torch.stack(images, dim=0), targets\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2, collate_fn=collate_fn)\n",
    "\n",
    "# Define model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, 1, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=128)\n",
    "\n",
    "        # linear layers\n",
    "        self.fc1 = nn.Linear(128*32*32, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # convolutional layers with batch normalization\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(F.relu(self.bn2(self.conv2(x))), 2)\n",
    "        x = F.max_pool2d(F.relu(self.bn3(self.conv3(x))), 2)\n",
    "\n",
    "        # flatten to feed into linear layers\n",
    "        x = x.view(-1, 128*32*32)\n",
    "        # linear layers\n",
    "        x = F.dropout(F.relu(self.fc1(x)), 0.5)\n",
    "        x = F.dropout(F.relu(self.fc2(x)), 0.5)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "def train(model, device, train_loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    print(1)\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        print(2)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "for epoch in range(1, 11):\n",
    "  train(model, device, train_loader, optimizer, criterion, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
