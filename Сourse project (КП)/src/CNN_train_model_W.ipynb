{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Batch [0/3720], Loss: 0.6759\n",
      "Epoch [1/15], Batch [100/3720], Loss: 0.6816\n",
      "Epoch [1/15], Batch [200/3720], Loss: 0.6617\n",
      "Epoch [1/15], Batch [300/3720], Loss: 0.6441\n",
      "Epoch [1/15], Batch [400/3720], Loss: 0.6796\n",
      "Epoch [1/15], Batch [500/3720], Loss: 0.6485\n",
      "Epoch [1/15], Batch [600/3720], Loss: 0.6500\n",
      "Epoch [1/15], Batch [700/3720], Loss: 0.5755\n",
      "Epoch [1/15], Batch [800/3720], Loss: 0.6081\n",
      "Epoch [1/15], Batch [900/3720], Loss: 0.6346\n",
      "Epoch [1/15], Batch [1000/3720], Loss: 0.6127\n",
      "Epoch [1/15], Batch [1100/3720], Loss: 0.6289\n",
      "Epoch [1/15], Batch [1200/3720], Loss: 0.5787\n",
      "Epoch [1/15], Batch [1300/3720], Loss: 0.7480\n",
      "Epoch [1/15], Batch [1400/3720], Loss: 0.6159\n",
      "Epoch [1/15], Batch [1500/3720], Loss: 0.5517\n",
      "Epoch [1/15], Batch [1600/3720], Loss: 0.6684\n",
      "Epoch [1/15], Batch [1700/3720], Loss: 0.6101\n",
      "Epoch [1/15], Batch [1800/3720], Loss: 0.6949\n",
      "Epoch [1/15], Batch [1900/3720], Loss: 0.6192\n",
      "Epoch [1/15], Batch [2000/3720], Loss: 0.6613\n",
      "Epoch [1/15], Batch [2100/3720], Loss: 0.6148\n",
      "Epoch [1/15], Batch [2200/3720], Loss: 0.6206\n",
      "Epoch [1/15], Batch [2300/3720], Loss: 0.6996\n",
      "Epoch [1/15], Batch [2400/3720], Loss: 0.5923\n",
      "Epoch [1/15], Batch [2500/3720], Loss: 0.6015\n",
      "Epoch [1/15], Batch [2600/3720], Loss: 0.7251\n",
      "Epoch [1/15], Batch [2700/3720], Loss: 0.6337\n",
      "Epoch [1/15], Batch [2800/3720], Loss: 0.5408\n",
      "Epoch [1/15], Batch [2900/3720], Loss: 0.6185\n",
      "Epoch [1/15], Batch [3000/3720], Loss: 0.5194\n",
      "Epoch [1/15], Batch [3100/3720], Loss: 0.5705\n",
      "Epoch [1/15], Batch [3200/3720], Loss: 0.6025\n",
      "Epoch [1/15], Batch [3300/3720], Loss: 0.6523\n",
      "Epoch [1/15], Batch [3400/3720], Loss: 0.6041\n",
      "Epoch [1/15], Batch [3500/3720], Loss: 0.6487\n",
      "Epoch [1/15], Batch [3600/3720], Loss: 0.6756\n",
      "Epoch [1/15], Batch [3700/3720], Loss: 0.5466\n",
      "Test Accuracy: 68.23%\n",
      "Epoch [2/15], Batch [0/3720], Loss: 0.6431\n",
      "Epoch [2/15], Batch [100/3720], Loss: 0.6248\n",
      "Epoch [2/15], Batch [200/3720], Loss: 0.5194\n",
      "Epoch [2/15], Batch [300/3720], Loss: 0.6410\n",
      "Epoch [2/15], Batch [400/3720], Loss: 0.5688\n",
      "Epoch [2/15], Batch [500/3720], Loss: 0.7158\n",
      "Epoch [2/15], Batch [600/3720], Loss: 0.4379\n",
      "Epoch [2/15], Batch [700/3720], Loss: 0.5874\n",
      "Epoch [2/15], Batch [800/3720], Loss: 0.6242\n",
      "Epoch [2/15], Batch [900/3720], Loss: 0.6625\n",
      "Epoch [2/15], Batch [1000/3720], Loss: 0.4738\n",
      "Epoch [2/15], Batch [1100/3720], Loss: 0.6198\n",
      "Epoch [2/15], Batch [1200/3720], Loss: 0.6132\n",
      "Epoch [2/15], Batch [1300/3720], Loss: 0.6417\n",
      "Epoch [2/15], Batch [1400/3720], Loss: 0.5906\n",
      "Epoch [2/15], Batch [1500/3720], Loss: 0.6153\n",
      "Epoch [2/15], Batch [1600/3720], Loss: 0.6187\n",
      "Epoch [2/15], Batch [1700/3720], Loss: 0.5736\n",
      "Epoch [2/15], Batch [1800/3720], Loss: 0.5882\n",
      "Epoch [2/15], Batch [1900/3720], Loss: 0.6448\n",
      "Epoch [2/15], Batch [2000/3720], Loss: 0.6016\n",
      "Epoch [2/15], Batch [2100/3720], Loss: 0.6248\n",
      "Epoch [2/15], Batch [2200/3720], Loss: 0.5323\n",
      "Epoch [2/15], Batch [2300/3720], Loss: 0.5314\n",
      "Epoch [2/15], Batch [2400/3720], Loss: 0.5843\n",
      "Epoch [2/15], Batch [2500/3720], Loss: 0.5294\n",
      "Epoch [2/15], Batch [2600/3720], Loss: 0.4271\n",
      "Epoch [2/15], Batch [2700/3720], Loss: 0.5805\n",
      "Epoch [2/15], Batch [2800/3720], Loss: 0.5371\n",
      "Epoch [2/15], Batch [2900/3720], Loss: 0.7255\n",
      "Epoch [2/15], Batch [3000/3720], Loss: 0.5704\n",
      "Epoch [2/15], Batch [3100/3720], Loss: 0.5994\n",
      "Epoch [2/15], Batch [3200/3720], Loss: 0.6638\n",
      "Epoch [2/15], Batch [3300/3720], Loss: 0.5933\n",
      "Epoch [2/15], Batch [3400/3720], Loss: 0.5847\n",
      "Epoch [2/15], Batch [3500/3720], Loss: 0.6987\n",
      "Epoch [2/15], Batch [3600/3720], Loss: 0.6292\n",
      "Epoch [2/15], Batch [3700/3720], Loss: 0.7067\n",
      "Test Accuracy: 69.49%\n",
      "Epoch [3/15], Batch [0/3720], Loss: 0.5591\n",
      "Epoch [3/15], Batch [100/3720], Loss: 0.7064\n",
      "Epoch [3/15], Batch [200/3720], Loss: 0.4366\n",
      "Epoch [3/15], Batch [300/3720], Loss: 0.6422\n",
      "Epoch [3/15], Batch [400/3720], Loss: 0.6586\n",
      "Epoch [3/15], Batch [500/3720], Loss: 0.5061\n",
      "Epoch [3/15], Batch [600/3720], Loss: 0.4720\n",
      "Epoch [3/15], Batch [700/3720], Loss: 0.6091\n",
      "Epoch [3/15], Batch [800/3720], Loss: 0.4687\n",
      "Epoch [3/15], Batch [900/3720], Loss: 0.4871\n",
      "Epoch [3/15], Batch [1000/3720], Loss: 0.5888\n",
      "Epoch [3/15], Batch [1100/3720], Loss: 0.5985\n",
      "Epoch [3/15], Batch [1200/3720], Loss: 0.5803\n",
      "Epoch [3/15], Batch [1300/3720], Loss: 0.5414\n",
      "Epoch [3/15], Batch [1400/3720], Loss: 0.4912\n",
      "Epoch [3/15], Batch [1500/3720], Loss: 0.4524\n",
      "Epoch [3/15], Batch [1600/3720], Loss: 0.5178\n",
      "Epoch [3/15], Batch [1700/3720], Loss: 0.6138\n",
      "Epoch [3/15], Batch [1800/3720], Loss: 0.5814\n",
      "Epoch [3/15], Batch [1900/3720], Loss: 0.7044\n",
      "Epoch [3/15], Batch [2000/3720], Loss: 0.4518\n",
      "Epoch [3/15], Batch [2100/3720], Loss: 0.6186\n",
      "Epoch [3/15], Batch [2200/3720], Loss: 0.4343\n",
      "Epoch [3/15], Batch [2300/3720], Loss: 0.8487\n",
      "Epoch [3/15], Batch [2400/3720], Loss: 0.8160\n",
      "Epoch [3/15], Batch [2500/3720], Loss: 0.5407\n",
      "Epoch [3/15], Batch [2600/3720], Loss: 0.5404\n",
      "Epoch [3/15], Batch [2700/3720], Loss: 0.3913\n",
      "Epoch [3/15], Batch [2800/3720], Loss: 0.5226\n",
      "Epoch [3/15], Batch [2900/3720], Loss: 0.8031\n",
      "Epoch [3/15], Batch [3000/3720], Loss: 0.6021\n",
      "Epoch [3/15], Batch [3100/3720], Loss: 0.5420\n",
      "Epoch [3/15], Batch [3200/3720], Loss: 0.6590\n",
      "Epoch [3/15], Batch [3300/3720], Loss: 0.6198\n",
      "Epoch [3/15], Batch [3400/3720], Loss: 0.5812\n",
      "Epoch [3/15], Batch [3500/3720], Loss: 0.3360\n",
      "Epoch [3/15], Batch [3600/3720], Loss: 0.6049\n",
      "Epoch [3/15], Batch [3700/3720], Loss: 0.5599\n",
      "Test Accuracy: 69.96%\n",
      "Epoch [4/15], Batch [0/3720], Loss: 0.4901\n",
      "Epoch [4/15], Batch [100/3720], Loss: 0.5384\n",
      "Epoch [4/15], Batch [200/3720], Loss: 0.5666\n",
      "Epoch [4/15], Batch [300/3720], Loss: 0.5745\n",
      "Epoch [4/15], Batch [400/3720], Loss: 0.4984\n",
      "Epoch [4/15], Batch [500/3720], Loss: 0.5499\n",
      "Epoch [4/15], Batch [600/3720], Loss: 0.4768\n",
      "Epoch [4/15], Batch [700/3720], Loss: 0.5937\n",
      "Epoch [4/15], Batch [800/3720], Loss: 0.4502\n",
      "Epoch [4/15], Batch [900/3720], Loss: 0.5600\n",
      "Epoch [4/15], Batch [1000/3720], Loss: 0.6161\n",
      "Epoch [4/15], Batch [1100/3720], Loss: 0.5803\n",
      "Epoch [4/15], Batch [1200/3720], Loss: 0.5449\n",
      "Epoch [4/15], Batch [1300/3720], Loss: 0.6862\n",
      "Epoch [4/15], Batch [1400/3720], Loss: 0.4097\n",
      "Epoch [4/15], Batch [1500/3720], Loss: 0.5602\n",
      "Epoch [4/15], Batch [1600/3720], Loss: 0.5048\n",
      "Epoch [4/15], Batch [1700/3720], Loss: 0.5572\n",
      "Epoch [4/15], Batch [1800/3720], Loss: 0.5685\n",
      "Epoch [4/15], Batch [1900/3720], Loss: 0.6005\n",
      "Epoch [4/15], Batch [2000/3720], Loss: 0.3867\n",
      "Epoch [4/15], Batch [2100/3720], Loss: 0.6174\n",
      "Epoch [4/15], Batch [2200/3720], Loss: 0.5265\n",
      "Epoch [4/15], Batch [2300/3720], Loss: 0.5324\n",
      "Epoch [4/15], Batch [2400/3720], Loss: 0.6490\n",
      "Epoch [4/15], Batch [2500/3720], Loss: 0.5436\n",
      "Epoch [4/15], Batch [2600/3720], Loss: 0.6612\n",
      "Epoch [4/15], Batch [2700/3720], Loss: 0.5775\n",
      "Epoch [4/15], Batch [2800/3720], Loss: 0.6554\n",
      "Epoch [4/15], Batch [2900/3720], Loss: 0.4311\n",
      "Epoch [4/15], Batch [3000/3720], Loss: 0.5613\n",
      "Epoch [4/15], Batch [3100/3720], Loss: 0.4545\n",
      "Epoch [4/15], Batch [3200/3720], Loss: 0.5929\n",
      "Epoch [4/15], Batch [3300/3720], Loss: 0.5207\n",
      "Epoch [4/15], Batch [3400/3720], Loss: 0.5022\n",
      "Epoch [4/15], Batch [3500/3720], Loss: 0.5522\n",
      "Epoch [4/15], Batch [3600/3720], Loss: 0.6440\n",
      "Epoch [4/15], Batch [3700/3720], Loss: 0.4285\n",
      "Test Accuracy: 70.98%\n",
      "Epoch [5/15], Batch [0/3720], Loss: 0.5967\n",
      "Epoch [5/15], Batch [100/3720], Loss: 0.5100\n",
      "Epoch [5/15], Batch [200/3720], Loss: 0.4838\n",
      "Epoch [5/15], Batch [300/3720], Loss: 0.5270\n",
      "Epoch [5/15], Batch [400/3720], Loss: 0.3911\n",
      "Epoch [5/15], Batch [500/3720], Loss: 0.5980\n",
      "Epoch [5/15], Batch [600/3720], Loss: 0.5932\n",
      "Epoch [5/15], Batch [700/3720], Loss: 0.7162\n",
      "Epoch [5/15], Batch [800/3720], Loss: 0.4779\n",
      "Epoch [5/15], Batch [900/3720], Loss: 0.6422\n",
      "Epoch [5/15], Batch [1000/3720], Loss: 0.5072\n",
      "Epoch [5/15], Batch [1100/3720], Loss: 0.5228\n",
      "Epoch [5/15], Batch [1200/3720], Loss: 0.4349\n",
      "Epoch [5/15], Batch [1300/3720], Loss: 0.4859\n",
      "Epoch [5/15], Batch [1400/3720], Loss: 0.3197\n",
      "Epoch [5/15], Batch [1500/3720], Loss: 0.4228\n",
      "Epoch [5/15], Batch [1600/3720], Loss: 0.4963\n",
      "Epoch [5/15], Batch [1700/3720], Loss: 0.6206\n",
      "Epoch [5/15], Batch [1800/3720], Loss: 0.4211\n",
      "Epoch [5/15], Batch [1900/3720], Loss: 0.4183\n",
      "Epoch [5/15], Batch [2000/3720], Loss: 0.5523\n",
      "Epoch [5/15], Batch [2100/3720], Loss: 0.5380\n",
      "Epoch [5/15], Batch [2200/3720], Loss: 0.6782\n",
      "Epoch [5/15], Batch [2300/3720], Loss: 0.5126\n",
      "Epoch [5/15], Batch [2400/3720], Loss: 0.5096\n",
      "Epoch [5/15], Batch [2500/3720], Loss: 0.6120\n",
      "Epoch [5/15], Batch [2600/3720], Loss: 0.4738\n",
      "Epoch [5/15], Batch [2700/3720], Loss: 0.4532\n",
      "Epoch [5/15], Batch [2800/3720], Loss: 0.4631\n",
      "Epoch [5/15], Batch [2900/3720], Loss: 0.5490\n",
      "Epoch [5/15], Batch [3000/3720], Loss: 0.5527\n",
      "Epoch [5/15], Batch [3100/3720], Loss: 0.4607\n",
      "Epoch [5/15], Batch [3200/3720], Loss: 0.5690\n",
      "Epoch [5/15], Batch [3300/3720], Loss: 0.5682\n",
      "Epoch [5/15], Batch [3400/3720], Loss: 0.4353\n",
      "Epoch [5/15], Batch [3500/3720], Loss: 0.5209\n",
      "Epoch [5/15], Batch [3600/3720], Loss: 0.3737\n",
      "Epoch [5/15], Batch [3700/3720], Loss: 0.4848\n",
      "Test Accuracy: 71.64%\n",
      "Epoch [6/15], Batch [0/3720], Loss: 0.4089\n",
      "Epoch [6/15], Batch [100/3720], Loss: 0.5668\n",
      "Epoch [6/15], Batch [200/3720], Loss: 0.4802\n",
      "Epoch [6/15], Batch [300/3720], Loss: 0.5464\n",
      "Epoch [6/15], Batch [400/3720], Loss: 0.4838\n",
      "Epoch [6/15], Batch [500/3720], Loss: 0.5017\n",
      "Epoch [6/15], Batch [600/3720], Loss: 0.4973\n",
      "Epoch [6/15], Batch [700/3720], Loss: 0.3954\n",
      "Epoch [6/15], Batch [800/3720], Loss: 0.5811\n",
      "Epoch [6/15], Batch [900/3720], Loss: 0.4943\n",
      "Epoch [6/15], Batch [1000/3720], Loss: 0.7631\n",
      "Epoch [6/15], Batch [1100/3720], Loss: 0.4797\n",
      "Epoch [6/15], Batch [1200/3720], Loss: 0.4284\n",
      "Epoch [6/15], Batch [1300/3720], Loss: 0.5700\n",
      "Epoch [6/15], Batch [1400/3720], Loss: 0.5316\n",
      "Epoch [6/15], Batch [1500/3720], Loss: 0.5977\n",
      "Epoch [6/15], Batch [1600/3720], Loss: 0.6425\n",
      "Epoch [6/15], Batch [1700/3720], Loss: 0.4695\n",
      "Epoch [6/15], Batch [1800/3720], Loss: 0.4656\n",
      "Epoch [6/15], Batch [1900/3720], Loss: 0.3095\n",
      "Epoch [6/15], Batch [2000/3720], Loss: 0.4273\n",
      "Epoch [6/15], Batch [2100/3720], Loss: 0.5686\n",
      "Epoch [6/15], Batch [2200/3720], Loss: 0.4295\n",
      "Epoch [6/15], Batch [2300/3720], Loss: 0.3930\n",
      "Epoch [6/15], Batch [2400/3720], Loss: 0.6255\n",
      "Epoch [6/15], Batch [2500/3720], Loss: 0.4824\n",
      "Epoch [6/15], Batch [2600/3720], Loss: 0.4796\n",
      "Epoch [6/15], Batch [2700/3720], Loss: 0.6242\n",
      "Epoch [6/15], Batch [2800/3720], Loss: 0.5375\n",
      "Epoch [6/15], Batch [2900/3720], Loss: 0.5328\n",
      "Epoch [6/15], Batch [3000/3720], Loss: 0.5714\n",
      "Epoch [6/15], Batch [3100/3720], Loss: 0.6399\n",
      "Epoch [6/15], Batch [3200/3720], Loss: 0.5685\n",
      "Epoch [6/15], Batch [3300/3720], Loss: 0.5676\n",
      "Epoch [6/15], Batch [3400/3720], Loss: 0.5627\n",
      "Epoch [6/15], Batch [3500/3720], Loss: 0.6190\n",
      "Epoch [6/15], Batch [3600/3720], Loss: 0.6299\n",
      "Epoch [6/15], Batch [3700/3720], Loss: 0.5419\n",
      "Test Accuracy: 71.26%\n",
      "Epoch [7/15], Batch [0/3720], Loss: 0.5402\n",
      "Epoch [7/15], Batch [100/3720], Loss: 0.4642\n",
      "Epoch [7/15], Batch [200/3720], Loss: 0.4739\n",
      "Epoch [7/15], Batch [300/3720], Loss: 0.4461\n",
      "Epoch [7/15], Batch [400/3720], Loss: 0.4396\n",
      "Epoch [7/15], Batch [500/3720], Loss: 0.5702\n",
      "Epoch [7/15], Batch [600/3720], Loss: 0.3914\n",
      "Epoch [7/15], Batch [700/3720], Loss: 0.3273\n",
      "Epoch [7/15], Batch [800/3720], Loss: 0.4979\n",
      "Epoch [7/15], Batch [900/3720], Loss: 0.4951\n",
      "Epoch [7/15], Batch [1000/3720], Loss: 0.5250\n",
      "Epoch [7/15], Batch [1100/3720], Loss: 0.4705\n",
      "Epoch [7/15], Batch [1200/3720], Loss: 0.4232\n",
      "Epoch [7/15], Batch [1300/3720], Loss: 0.3846\n",
      "Epoch [7/15], Batch [1400/3720], Loss: 0.3778\n",
      "Epoch [7/15], Batch [1500/3720], Loss: 0.5112\n",
      "Epoch [7/15], Batch [1600/3720], Loss: 0.4331\n",
      "Epoch [7/15], Batch [1700/3720], Loss: 0.5522\n",
      "Epoch [7/15], Batch [1800/3720], Loss: 0.4914\n",
      "Epoch [7/15], Batch [1900/3720], Loss: 0.4898\n",
      "Epoch [7/15], Batch [2000/3720], Loss: 0.4081\n",
      "Epoch [7/15], Batch [2100/3720], Loss: 0.5466\n",
      "Epoch [7/15], Batch [2200/3720], Loss: 0.3885\n",
      "Epoch [7/15], Batch [2300/3720], Loss: 0.4578\n",
      "Epoch [7/15], Batch [2400/3720], Loss: 0.3414\n",
      "Epoch [7/15], Batch [2500/3720], Loss: 0.5416\n",
      "Epoch [7/15], Batch [2600/3720], Loss: 0.4751\n",
      "Epoch [7/15], Batch [2700/3720], Loss: 0.4119\n",
      "Epoch [7/15], Batch [2800/3720], Loss: 0.7127\n",
      "Epoch [7/15], Batch [2900/3720], Loss: 0.6334\n",
      "Epoch [7/15], Batch [3000/3720], Loss: 0.4941\n",
      "Epoch [7/15], Batch [3100/3720], Loss: 0.3497\n",
      "Epoch [7/15], Batch [3200/3720], Loss: 0.4554\n",
      "Epoch [7/15], Batch [3300/3720], Loss: 0.5288\n",
      "Epoch [7/15], Batch [3400/3720], Loss: 0.4435\n",
      "Epoch [7/15], Batch [3500/3720], Loss: 0.5490\n",
      "Epoch [7/15], Batch [3600/3720], Loss: 0.6868\n",
      "Epoch [7/15], Batch [3700/3720], Loss: 0.3745\n",
      "Test Accuracy: 71.50%\n",
      "Epoch [8/15], Batch [0/3720], Loss: 0.5139\n",
      "Epoch [8/15], Batch [100/3720], Loss: 0.4792\n",
      "Epoch [8/15], Batch [200/3720], Loss: 0.6054\n",
      "Epoch [8/15], Batch [300/3720], Loss: 0.5786\n",
      "Epoch [8/15], Batch [400/3720], Loss: 0.4696\n",
      "Epoch [8/15], Batch [500/3720], Loss: 0.4583\n",
      "Epoch [8/15], Batch [600/3720], Loss: 0.5226\n",
      "Epoch [8/15], Batch [700/3720], Loss: 0.4215\n",
      "Epoch [8/15], Batch [800/3720], Loss: 0.5865\n",
      "Epoch [8/15], Batch [900/3720], Loss: 0.5919\n",
      "Epoch [8/15], Batch [1000/3720], Loss: 0.5522\n",
      "Epoch [8/15], Batch [1100/3720], Loss: 0.5315\n",
      "Epoch [8/15], Batch [1200/3720], Loss: 0.4532\n",
      "Epoch [8/15], Batch [1300/3720], Loss: 0.6172\n",
      "Epoch [8/15], Batch [1400/3720], Loss: 0.5141\n",
      "Epoch [8/15], Batch [1500/3720], Loss: 0.3855\n",
      "Epoch [8/15], Batch [1600/3720], Loss: 0.4975\n",
      "Epoch [8/15], Batch [1700/3720], Loss: 0.4495\n",
      "Epoch [8/15], Batch [1800/3720], Loss: 0.4050\n",
      "Epoch [8/15], Batch [1900/3720], Loss: 0.4305\n",
      "Epoch [8/15], Batch [2000/3720], Loss: 0.4256\n",
      "Epoch [8/15], Batch [2100/3720], Loss: 0.5360\n",
      "Epoch [8/15], Batch [2200/3720], Loss: 0.6802\n",
      "Epoch [8/15], Batch [2300/3720], Loss: 0.3495\n",
      "Epoch [8/15], Batch [2400/3720], Loss: 0.6567\n",
      "Epoch [8/15], Batch [2500/3720], Loss: 0.7155\n",
      "Epoch [8/15], Batch [2600/3720], Loss: 0.6209\n",
      "Epoch [8/15], Batch [2700/3720], Loss: 0.5373\n",
      "Epoch [8/15], Batch [2800/3720], Loss: 0.5461\n",
      "Epoch [8/15], Batch [2900/3720], Loss: 0.4135\n",
      "Epoch [8/15], Batch [3000/3720], Loss: 0.4109\n",
      "Epoch [8/15], Batch [3100/3720], Loss: 0.6610\n",
      "Epoch [8/15], Batch [3200/3720], Loss: 0.5175\n",
      "Epoch [8/15], Batch [3300/3720], Loss: 0.3269\n",
      "Epoch [8/15], Batch [3400/3720], Loss: 0.3846\n",
      "Epoch [8/15], Batch [3500/3720], Loss: 0.5185\n",
      "Epoch [8/15], Batch [3600/3720], Loss: 0.4644\n",
      "Epoch [8/15], Batch [3700/3720], Loss: 0.4062\n",
      "Test Accuracy: 72.25%\n",
      "Epoch [9/15], Batch [0/3720], Loss: 0.3813\n",
      "Epoch [9/15], Batch [100/3720], Loss: 0.5050\n",
      "Epoch [9/15], Batch [200/3720], Loss: 0.3410\n",
      "Epoch [9/15], Batch [300/3720], Loss: 0.4636\n",
      "Epoch [9/15], Batch [400/3720], Loss: 0.3924\n",
      "Epoch [9/15], Batch [500/3720], Loss: 0.3573\n",
      "Epoch [9/15], Batch [600/3720], Loss: 0.3484\n",
      "Epoch [9/15], Batch [700/3720], Loss: 0.3839\n",
      "Epoch [9/15], Batch [800/3720], Loss: 0.5031\n",
      "Epoch [9/15], Batch [900/3720], Loss: 0.3920\n",
      "Epoch [9/15], Batch [1000/3720], Loss: 0.4278\n",
      "Epoch [9/15], Batch [1100/3720], Loss: 0.4412\n",
      "Epoch [9/15], Batch [1200/3720], Loss: 0.4394\n",
      "Epoch [9/15], Batch [1300/3720], Loss: 0.5272\n",
      "Epoch [9/15], Batch [1400/3720], Loss: 0.5058\n",
      "Epoch [9/15], Batch [1500/3720], Loss: 0.3364\n",
      "Epoch [9/15], Batch [1600/3720], Loss: 0.5295\n",
      "Epoch [9/15], Batch [1700/3720], Loss: 0.5959\n",
      "Epoch [9/15], Batch [1800/3720], Loss: 0.4782\n",
      "Epoch [9/15], Batch [1900/3720], Loss: 0.3126\n",
      "Epoch [9/15], Batch [2000/3720], Loss: 0.5706\n",
      "Epoch [9/15], Batch [2100/3720], Loss: 0.4640\n",
      "Epoch [9/15], Batch [2200/3720], Loss: 0.4273\n",
      "Epoch [9/15], Batch [2300/3720], Loss: 0.5980\n",
      "Epoch [9/15], Batch [2400/3720], Loss: 0.3317\n",
      "Epoch [9/15], Batch [2500/3720], Loss: 0.3095\n",
      "Epoch [9/15], Batch [2600/3720], Loss: 0.3556\n",
      "Epoch [9/15], Batch [2700/3720], Loss: 0.5301\n",
      "Epoch [9/15], Batch [2800/3720], Loss: 0.3425\n",
      "Epoch [9/15], Batch [2900/3720], Loss: 0.2617\n",
      "Epoch [9/15], Batch [3000/3720], Loss: 0.5722\n",
      "Epoch [9/15], Batch [3100/3720], Loss: 0.4195\n",
      "Epoch [9/15], Batch [3200/3720], Loss: 0.4826\n",
      "Epoch [9/15], Batch [3300/3720], Loss: 0.4774\n",
      "Epoch [9/15], Batch [3400/3720], Loss: 0.4836\n",
      "Epoch [9/15], Batch [3500/3720], Loss: 0.5692\n",
      "Epoch [9/15], Batch [3600/3720], Loss: 0.5333\n",
      "Epoch [9/15], Batch [3700/3720], Loss: 0.2789\n",
      "Test Accuracy: 72.41%\n",
      "Epoch [10/15], Batch [0/3720], Loss: 0.2949\n",
      "Epoch [10/15], Batch [100/3720], Loss: 0.3089\n",
      "Epoch [10/15], Batch [200/3720], Loss: 0.4882\n",
      "Epoch [10/15], Batch [300/3720], Loss: 0.3985\n",
      "Epoch [10/15], Batch [400/3720], Loss: 0.3032\n",
      "Epoch [10/15], Batch [500/3720], Loss: 0.3055\n",
      "Epoch [10/15], Batch [600/3720], Loss: 0.4683\n",
      "Epoch [10/15], Batch [700/3720], Loss: 0.4098\n",
      "Epoch [10/15], Batch [800/3720], Loss: 0.3945\n",
      "Epoch [10/15], Batch [900/3720], Loss: 0.5310\n",
      "Epoch [10/15], Batch [1000/3720], Loss: 0.4713\n",
      "Epoch [10/15], Batch [1100/3720], Loss: 0.4254\n",
      "Epoch [10/15], Batch [1200/3720], Loss: 0.4302\n",
      "Epoch [10/15], Batch [1300/3720], Loss: 0.4398\n",
      "Epoch [10/15], Batch [1400/3720], Loss: 0.5478\n",
      "Epoch [10/15], Batch [1500/3720], Loss: 0.6380\n",
      "Epoch [10/15], Batch [1600/3720], Loss: 0.3856\n",
      "Epoch [10/15], Batch [1700/3720], Loss: 0.2471\n",
      "Epoch [10/15], Batch [1800/3720], Loss: 0.3169\n",
      "Epoch [10/15], Batch [1900/3720], Loss: 0.2956\n",
      "Epoch [10/15], Batch [2000/3720], Loss: 0.4684\n",
      "Epoch [10/15], Batch [2100/3720], Loss: 0.2852\n",
      "Epoch [10/15], Batch [2200/3720], Loss: 0.3672\n",
      "Epoch [10/15], Batch [2300/3720], Loss: 0.3006\n",
      "Epoch [10/15], Batch [2400/3720], Loss: 0.4820\n",
      "Epoch [10/15], Batch [2500/3720], Loss: 0.3604\n",
      "Epoch [10/15], Batch [2600/3720], Loss: 0.4381\n",
      "Epoch [10/15], Batch [2700/3720], Loss: 0.3807\n",
      "Epoch [10/15], Batch [2800/3720], Loss: 0.4901\n",
      "Epoch [10/15], Batch [2900/3720], Loss: 0.7190\n",
      "Epoch [10/15], Batch [3000/3720], Loss: 0.4800\n",
      "Epoch [10/15], Batch [3100/3720], Loss: 0.3381\n",
      "Epoch [10/15], Batch [3200/3720], Loss: 0.4358\n",
      "Epoch [10/15], Batch [3300/3720], Loss: 0.4614\n",
      "Epoch [10/15], Batch [3400/3720], Loss: 0.4705\n",
      "Epoch [10/15], Batch [3500/3720], Loss: 0.5231\n",
      "Epoch [10/15], Batch [3600/3720], Loss: 0.4851\n",
      "Epoch [10/15], Batch [3700/3720], Loss: 0.4937\n",
      "Test Accuracy: 70.28%\n",
      "Epoch [11/15], Batch [0/3720], Loss: 0.4060\n",
      "Epoch [11/15], Batch [100/3720], Loss: 0.3862\n",
      "Epoch [11/15], Batch [200/3720], Loss: 0.3776\n",
      "Epoch [11/15], Batch [300/3720], Loss: 0.5544\n",
      "Epoch [11/15], Batch [400/3720], Loss: 0.4840\n",
      "Epoch [11/15], Batch [500/3720], Loss: 0.4846\n",
      "Epoch [11/15], Batch [600/3720], Loss: 0.3389\n",
      "Epoch [11/15], Batch [700/3720], Loss: 0.4393\n",
      "Epoch [11/15], Batch [800/3720], Loss: 0.4519\n",
      "Epoch [11/15], Batch [900/3720], Loss: 0.4560\n",
      "Epoch [11/15], Batch [1000/3720], Loss: 0.4335\n",
      "Epoch [11/15], Batch [1100/3720], Loss: 0.3753\n",
      "Epoch [11/15], Batch [1200/3720], Loss: 0.4881\n",
      "Epoch [11/15], Batch [1300/3720], Loss: 0.4170\n",
      "Epoch [11/15], Batch [1400/3720], Loss: 0.4088\n",
      "Epoch [11/15], Batch [1500/3720], Loss: 0.3582\n",
      "Epoch [11/15], Batch [1600/3720], Loss: 0.3825\n",
      "Epoch [11/15], Batch [1700/3720], Loss: 0.4096\n",
      "Epoch [11/15], Batch [1800/3720], Loss: 0.5652\n",
      "Epoch [11/15], Batch [1900/3720], Loss: 0.3581\n",
      "Epoch [11/15], Batch [2000/3720], Loss: 0.3339\n",
      "Epoch [11/15], Batch [2100/3720], Loss: 0.3610\n",
      "Epoch [11/15], Batch [2200/3720], Loss: 0.3308\n",
      "Epoch [11/15], Batch [2300/3720], Loss: 0.3442\n",
      "Epoch [11/15], Batch [2400/3720], Loss: 0.5438\n",
      "Epoch [11/15], Batch [2500/3720], Loss: 0.3673\n",
      "Epoch [11/15], Batch [2600/3720], Loss: 0.2714\n",
      "Epoch [11/15], Batch [2700/3720], Loss: 0.3665\n",
      "Epoch [11/15], Batch [2800/3720], Loss: 0.4693\n",
      "Epoch [11/15], Batch [2900/3720], Loss: 0.2888\n",
      "Epoch [11/15], Batch [3000/3720], Loss: 0.3579\n",
      "Epoch [11/15], Batch [3100/3720], Loss: 0.3790\n",
      "Epoch [11/15], Batch [3200/3720], Loss: 0.4239\n",
      "Epoch [11/15], Batch [3300/3720], Loss: 0.2609\n",
      "Epoch [11/15], Batch [3400/3720], Loss: 0.3816\n",
      "Epoch [11/15], Batch [3500/3720], Loss: 0.3232\n",
      "Epoch [11/15], Batch [3600/3720], Loss: 0.3657\n",
      "Epoch [11/15], Batch [3700/3720], Loss: 0.5859\n",
      "Test Accuracy: 71.28%\n",
      "Epoch [12/15], Batch [0/3720], Loss: 0.3196\n",
      "Epoch [12/15], Batch [100/3720], Loss: 0.3848\n",
      "Epoch [12/15], Batch [200/3720], Loss: 0.3570\n",
      "Epoch [12/15], Batch [300/3720], Loss: 0.5109\n",
      "Epoch [12/15], Batch [400/3720], Loss: 0.3355\n",
      "Epoch [12/15], Batch [500/3720], Loss: 0.4465\n",
      "Epoch [12/15], Batch [600/3720], Loss: 0.2519\n",
      "Epoch [12/15], Batch [700/3720], Loss: 0.6301\n",
      "Epoch [12/15], Batch [800/3720], Loss: 0.2457\n",
      "Epoch [12/15], Batch [900/3720], Loss: 0.3802\n",
      "Epoch [12/15], Batch [1000/3720], Loss: 0.4067\n",
      "Epoch [12/15], Batch [1100/3720], Loss: 0.3361\n",
      "Epoch [12/15], Batch [1200/3720], Loss: 0.4403\n",
      "Epoch [12/15], Batch [1300/3720], Loss: 0.4415\n",
      "Epoch [12/15], Batch [1400/3720], Loss: 0.3794\n",
      "Epoch [12/15], Batch [1500/3720], Loss: 0.3593\n",
      "Epoch [12/15], Batch [1600/3720], Loss: 0.3528\n",
      "Epoch [12/15], Batch [1700/3720], Loss: 0.2498\n",
      "Epoch [12/15], Batch [1800/3720], Loss: 0.4578\n",
      "Epoch [12/15], Batch [1900/3720], Loss: 0.4925\n",
      "Epoch [12/15], Batch [2000/3720], Loss: 0.3763\n",
      "Epoch [12/15], Batch [2100/3720], Loss: 0.3535\n",
      "Epoch [12/15], Batch [2200/3720], Loss: 0.5416\n",
      "Epoch [12/15], Batch [2300/3720], Loss: 0.3330\n",
      "Epoch [12/15], Batch [2400/3720], Loss: 0.3352\n",
      "Epoch [12/15], Batch [2500/3720], Loss: 0.5189\n",
      "Epoch [12/15], Batch [2600/3720], Loss: 0.5093\n",
      "Epoch [12/15], Batch [2700/3720], Loss: 0.2977\n",
      "Epoch [12/15], Batch [2800/3720], Loss: 0.2844\n",
      "Epoch [12/15], Batch [2900/3720], Loss: 0.6679\n",
      "Epoch [12/15], Batch [3000/3720], Loss: 0.3088\n",
      "Epoch [12/15], Batch [3100/3720], Loss: 0.3700\n",
      "Epoch [12/15], Batch [3200/3720], Loss: 0.4056\n",
      "Epoch [12/15], Batch [3300/3720], Loss: 0.3952\n",
      "Epoch [12/15], Batch [3400/3720], Loss: 0.4020\n",
      "Epoch [12/15], Batch [3500/3720], Loss: 0.3535\n",
      "Epoch [12/15], Batch [3600/3720], Loss: 0.2970\n",
      "Epoch [12/15], Batch [3700/3720], Loss: 0.3777\n",
      "Test Accuracy: 70.74%\n",
      "Epoch [13/15], Batch [0/3720], Loss: 0.3090\n",
      "Epoch [13/15], Batch [100/3720], Loss: 0.4741\n",
      "Epoch [13/15], Batch [200/3720], Loss: 0.4037\n",
      "Epoch [13/15], Batch [300/3720], Loss: 0.3960\n",
      "Epoch [13/15], Batch [400/3720], Loss: 0.2457\n",
      "Epoch [13/15], Batch [500/3720], Loss: 0.2403\n",
      "Epoch [13/15], Batch [600/3720], Loss: 0.3798\n",
      "Epoch [13/15], Batch [700/3720], Loss: 0.2714\n",
      "Epoch [13/15], Batch [800/3720], Loss: 0.3183\n",
      "Epoch [13/15], Batch [900/3720], Loss: 0.1395\n",
      "Epoch [13/15], Batch [1000/3720], Loss: 0.3412\n",
      "Epoch [13/15], Batch [1100/3720], Loss: 0.1307\n",
      "Epoch [13/15], Batch [1200/3720], Loss: 0.4555\n",
      "Epoch [13/15], Batch [1300/3720], Loss: 0.3439\n",
      "Epoch [13/15], Batch [1400/3720], Loss: 0.2719\n",
      "Epoch [13/15], Batch [1500/3720], Loss: 0.3018\n",
      "Epoch [13/15], Batch [1600/3720], Loss: 0.2839\n",
      "Epoch [13/15], Batch [1700/3720], Loss: 0.4373\n",
      "Epoch [13/15], Batch [1800/3720], Loss: 0.4539\n",
      "Epoch [13/15], Batch [1900/3720], Loss: 0.4557\n",
      "Epoch [13/15], Batch [2000/3720], Loss: 0.3411\n",
      "Epoch [13/15], Batch [2100/3720], Loss: 0.3670\n",
      "Epoch [13/15], Batch [2200/3720], Loss: 0.4606\n",
      "Epoch [13/15], Batch [2300/3720], Loss: 0.5550\n",
      "Epoch [13/15], Batch [2400/3720], Loss: 0.2388\n",
      "Epoch [13/15], Batch [2500/3720], Loss: 0.3394\n",
      "Epoch [13/15], Batch [2600/3720], Loss: 0.2131\n",
      "Epoch [13/15], Batch [2700/3720], Loss: 0.3742\n",
      "Epoch [13/15], Batch [2800/3720], Loss: 0.6068\n",
      "Epoch [13/15], Batch [2900/3720], Loss: 0.3970\n",
      "Epoch [13/15], Batch [3000/3720], Loss: 0.3893\n",
      "Epoch [13/15], Batch [3100/3720], Loss: 0.3547\n",
      "Epoch [13/15], Batch [3200/3720], Loss: 0.3619\n",
      "Epoch [13/15], Batch [3300/3720], Loss: 0.2977\n",
      "Epoch [13/15], Batch [3400/3720], Loss: 0.2213\n",
      "Epoch [13/15], Batch [3500/3720], Loss: 0.4191\n",
      "Epoch [13/15], Batch [3600/3720], Loss: 0.2429\n",
      "Epoch [13/15], Batch [3700/3720], Loss: 0.4155\n",
      "Test Accuracy: 70.46%\n",
      "Epoch [14/15], Batch [0/3720], Loss: 0.4922\n",
      "Epoch [14/15], Batch [100/3720], Loss: 0.2819\n",
      "Epoch [14/15], Batch [200/3720], Loss: 0.3191\n",
      "Epoch [14/15], Batch [300/3720], Loss: 0.3518\n",
      "Epoch [14/15], Batch [400/3720], Loss: 0.5669\n",
      "Epoch [14/15], Batch [500/3720], Loss: 0.1545\n",
      "Epoch [14/15], Batch [600/3720], Loss: 0.3463\n",
      "Epoch [14/15], Batch [700/3720], Loss: 0.3034\n",
      "Epoch [14/15], Batch [800/3720], Loss: 0.2064\n",
      "Epoch [14/15], Batch [900/3720], Loss: 0.3882\n",
      "Epoch [14/15], Batch [1000/3720], Loss: 0.2980\n",
      "Epoch [14/15], Batch [1100/3720], Loss: 0.3408\n",
      "Epoch [14/15], Batch [1200/3720], Loss: 0.4270\n",
      "Epoch [14/15], Batch [1300/3720], Loss: 0.4037\n",
      "Epoch [14/15], Batch [1400/3720], Loss: 0.2184\n",
      "Epoch [14/15], Batch [1500/3720], Loss: 0.4422\n",
      "Epoch [14/15], Batch [1600/3720], Loss: 0.3212\n",
      "Epoch [14/15], Batch [1700/3720], Loss: 0.1984\n",
      "Epoch [14/15], Batch [1800/3720], Loss: 0.4710\n",
      "Epoch [14/15], Batch [1900/3720], Loss: 0.3351\n",
      "Epoch [14/15], Batch [2000/3720], Loss: 0.5700\n",
      "Epoch [14/15], Batch [2100/3720], Loss: 0.3074\n",
      "Epoch [14/15], Batch [2200/3720], Loss: 0.2186\n",
      "Epoch [14/15], Batch [2300/3720], Loss: 0.4167\n",
      "Epoch [14/15], Batch [2400/3720], Loss: 0.2899\n",
      "Epoch [14/15], Batch [2500/3720], Loss: 0.3162\n",
      "Epoch [14/15], Batch [2600/3720], Loss: 0.3441\n",
      "Epoch [14/15], Batch [2700/3720], Loss: 0.4201\n",
      "Epoch [14/15], Batch [2800/3720], Loss: 0.4133\n",
      "Epoch [14/15], Batch [2900/3720], Loss: 0.4042\n",
      "Epoch [14/15], Batch [3000/3720], Loss: 0.4137\n",
      "Epoch [14/15], Batch [3100/3720], Loss: 0.3391\n",
      "Epoch [14/15], Batch [3200/3720], Loss: 0.3125\n",
      "Epoch [14/15], Batch [3300/3720], Loss: 0.3793\n",
      "Epoch [14/15], Batch [3400/3720], Loss: 0.3394\n",
      "Epoch [14/15], Batch [3500/3720], Loss: 0.2159\n",
      "Epoch [14/15], Batch [3600/3720], Loss: 0.3453\n",
      "Epoch [14/15], Batch [3700/3720], Loss: 0.3573\n",
      "Test Accuracy: 70.24%\n",
      "Epoch [15/15], Batch [0/3720], Loss: 0.2419\n",
      "Epoch [15/15], Batch [100/3720], Loss: 0.2243\n",
      "Epoch [15/15], Batch [200/3720], Loss: 0.2388\n",
      "Epoch [15/15], Batch [300/3720], Loss: 0.2957\n",
      "Epoch [15/15], Batch [400/3720], Loss: 0.3921\n",
      "Epoch [15/15], Batch [500/3720], Loss: 0.2290\n",
      "Epoch [15/15], Batch [600/3720], Loss: 0.1835\n",
      "Epoch [15/15], Batch [700/3720], Loss: 0.2471\n",
      "Epoch [15/15], Batch [800/3720], Loss: 0.1764\n",
      "Epoch [15/15], Batch [900/3720], Loss: 0.3005\n",
      "Epoch [15/15], Batch [1000/3720], Loss: 0.2096\n",
      "Epoch [15/15], Batch [1100/3720], Loss: 0.3202\n",
      "Epoch [15/15], Batch [1200/3720], Loss: 0.2926\n",
      "Epoch [15/15], Batch [1300/3720], Loss: 0.3775\n",
      "Epoch [15/15], Batch [1400/3720], Loss: 0.2128\n",
      "Epoch [15/15], Batch [1500/3720], Loss: 0.3242\n",
      "Epoch [15/15], Batch [1600/3720], Loss: 0.1756\n",
      "Epoch [15/15], Batch [1700/3720], Loss: 0.2216\n",
      "Epoch [15/15], Batch [1800/3720], Loss: 0.4204\n",
      "Epoch [15/15], Batch [1900/3720], Loss: 0.2402\n",
      "Epoch [15/15], Batch [2000/3720], Loss: 0.4802\n",
      "Epoch [15/15], Batch [2100/3720], Loss: 0.4579\n",
      "Epoch [15/15], Batch [2200/3720], Loss: 0.3998\n",
      "Epoch [15/15], Batch [2300/3720], Loss: 0.4669\n",
      "Epoch [15/15], Batch [2400/3720], Loss: 0.1721\n",
      "Epoch [15/15], Batch [2500/3720], Loss: 0.5486\n",
      "Epoch [15/15], Batch [2600/3720], Loss: 0.3772\n",
      "Epoch [15/15], Batch [2700/3720], Loss: 0.2906\n",
      "Epoch [15/15], Batch [2800/3720], Loss: 0.2849\n",
      "Epoch [15/15], Batch [2900/3720], Loss: 0.5316\n",
      "Epoch [15/15], Batch [3000/3720], Loss: 0.3978\n",
      "Epoch [15/15], Batch [3100/3720], Loss: 0.3877\n",
      "Epoch [15/15], Batch [3200/3720], Loss: 0.3506\n",
      "Epoch [15/15], Batch [3300/3720], Loss: 0.4362\n",
      "Epoch [15/15], Batch [3400/3720], Loss: 0.2787\n",
      "Epoch [15/15], Batch [3500/3720], Loss: 0.1345\n",
      "Epoch [15/15], Batch [3600/3720], Loss: 0.1571\n",
      "Epoch [15/15], Batch [3700/3720], Loss: 0.2477\n",
      "Test Accuracy: 69.49%\n",
      "Модель создана\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the neural network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 8 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 32 * 8 * 8)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Define the dataset and data loader\n",
    "train_folder = 'D:/Курсовой проект/train'\n",
    "test_folder =  'D:/Курсовой проект/test'\n",
    "transform = transforms.Compose([transforms.Resize((32,32)),transforms.ToTensor()])\n",
    "train_dataset = datasets.ImageFolder(train_folder, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_folder, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Instantiate the neural network and define the loss function and optimizer\n",
    "model = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# print(torch.__version__)\n",
    "\n",
    "# Train the neural network\n",
    "for epoch in range(15):\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print training progress\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{15}], Batch [{batch_idx}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    # Evaluate the neural network on the test set\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data, targets in test_loader:\n",
    "            scores = model(data)\n",
    "            _, predicted = torch.max(scores.data, 1)\n",
    "            total += targets.size(  0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "torch.save(model.state_dict(), 'person_detection_model.pth')\n",
    "print('Модель создана')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
