{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Batch [0/507], Loss: 0.6982\n",
      "Epoch [1/15], Batch [100/507], Loss: 0.7770\n",
      "Epoch [1/15], Batch [200/507], Loss: 0.6781\n",
      "Epoch [1/15], Batch [300/507], Loss: 0.4952\n",
      "Epoch [1/15], Batch [400/507], Loss: 0.5029\n",
      "Epoch [1/15], Batch [500/507], Loss: 0.4651\n",
      "Test Accuracy: 65.78%\n",
      "Epoch [2/15], Batch [0/507], Loss: 0.6343\n",
      "Epoch [2/15], Batch [100/507], Loss: 0.3066\n",
      "Epoch [2/15], Batch [200/507], Loss: 0.4285\n",
      "Epoch [2/15], Batch [300/507], Loss: 0.4703\n",
      "Epoch [2/15], Batch [400/507], Loss: 0.6113\n",
      "Epoch [2/15], Batch [500/507], Loss: 0.5117\n",
      "Test Accuracy: 65.22%\n",
      "Epoch [3/15], Batch [0/507], Loss: 0.4915\n",
      "Epoch [3/15], Batch [100/507], Loss: 0.4295\n",
      "Epoch [3/15], Batch [200/507], Loss: 0.4703\n",
      "Epoch [3/15], Batch [300/507], Loss: 0.5786\n",
      "Epoch [3/15], Batch [400/507], Loss: 0.4021\n",
      "Epoch [3/15], Batch [500/507], Loss: 0.4815\n",
      "Test Accuracy: 67.83%\n",
      "Epoch [4/15], Batch [0/507], Loss: 0.4415\n",
      "Epoch [4/15], Batch [100/507], Loss: 0.3642\n",
      "Epoch [4/15], Batch [200/507], Loss: 0.5346\n",
      "Epoch [4/15], Batch [300/507], Loss: 0.5059\n",
      "Epoch [4/15], Batch [400/507], Loss: 0.4532\n",
      "Epoch [4/15], Batch [500/507], Loss: 0.4102\n",
      "Test Accuracy: 70.03%\n",
      "Epoch [5/15], Batch [0/507], Loss: 0.4750\n",
      "Epoch [5/15], Batch [100/507], Loss: 0.3626\n",
      "Epoch [5/15], Batch [200/507], Loss: 0.3134\n",
      "Epoch [5/15], Batch [300/507], Loss: 0.3901\n",
      "Epoch [5/15], Batch [400/507], Loss: 0.3386\n",
      "Epoch [5/15], Batch [500/507], Loss: 0.3324\n",
      "Test Accuracy: 69.35%\n",
      "Epoch [6/15], Batch [0/507], Loss: 0.3701\n",
      "Epoch [6/15], Batch [100/507], Loss: 0.3521\n",
      "Epoch [6/15], Batch [200/507], Loss: 0.4742\n",
      "Epoch [6/15], Batch [300/507], Loss: 0.4140\n",
      "Epoch [6/15], Batch [400/507], Loss: 0.3182\n",
      "Epoch [6/15], Batch [500/507], Loss: 0.4090\n",
      "Test Accuracy: 70.22%\n",
      "Epoch [7/15], Batch [0/507], Loss: 0.3795\n",
      "Epoch [7/15], Batch [100/507], Loss: 0.2889\n",
      "Epoch [7/15], Batch [200/507], Loss: 0.2595\n",
      "Epoch [7/15], Batch [300/507], Loss: 0.4079\n",
      "Epoch [7/15], Batch [400/507], Loss: 0.3103\n",
      "Epoch [7/15], Batch [500/507], Loss: 0.2713\n",
      "Test Accuracy: 69.35%\n",
      "Epoch [8/15], Batch [0/507], Loss: 0.3585\n",
      "Epoch [8/15], Batch [100/507], Loss: 0.3661\n",
      "Epoch [8/15], Batch [200/507], Loss: 0.4002\n",
      "Epoch [8/15], Batch [300/507], Loss: 0.3272\n",
      "Epoch [8/15], Batch [400/507], Loss: 0.2975\n",
      "Epoch [8/15], Batch [500/507], Loss: 0.2798\n",
      "Test Accuracy: 70.69%\n",
      "Epoch [9/15], Batch [0/507], Loss: 0.3430\n",
      "Epoch [9/15], Batch [100/507], Loss: 0.6466\n",
      "Epoch [9/15], Batch [200/507], Loss: 0.2547\n",
      "Epoch [9/15], Batch [300/507], Loss: 0.1600\n",
      "Epoch [9/15], Batch [400/507], Loss: 0.3997\n",
      "Epoch [9/15], Batch [500/507], Loss: 0.2637\n",
      "Test Accuracy: 70.47%\n",
      "Epoch [10/15], Batch [0/507], Loss: 0.3316\n",
      "Epoch [10/15], Batch [100/507], Loss: 0.4142\n",
      "Epoch [10/15], Batch [200/507], Loss: 0.2872\n",
      "Epoch [10/15], Batch [300/507], Loss: 0.1049\n",
      "Epoch [10/15], Batch [400/507], Loss: 0.2212\n",
      "Epoch [10/15], Batch [500/507], Loss: 0.2044\n",
      "Test Accuracy: 70.44%\n",
      "Epoch [11/15], Batch [0/507], Loss: 0.1943\n",
      "Epoch [11/15], Batch [100/507], Loss: 0.2748\n",
      "Epoch [11/15], Batch [200/507], Loss: 0.2973\n",
      "Epoch [11/15], Batch [300/507], Loss: 0.2715\n",
      "Epoch [11/15], Batch [400/507], Loss: 0.4110\n",
      "Epoch [11/15], Batch [500/507], Loss: 0.2043\n",
      "Test Accuracy: 69.27%\n",
      "Epoch [12/15], Batch [0/507], Loss: 0.1807\n",
      "Epoch [12/15], Batch [100/507], Loss: 0.2165\n",
      "Epoch [12/15], Batch [200/507], Loss: 0.2016\n",
      "Epoch [12/15], Batch [300/507], Loss: 0.1882\n",
      "Epoch [12/15], Batch [400/507], Loss: 0.1498\n",
      "Epoch [12/15], Batch [500/507], Loss: 0.1440\n",
      "Test Accuracy: 70.91%\n",
      "Epoch [13/15], Batch [0/507], Loss: 0.1136\n",
      "Epoch [13/15], Batch [100/507], Loss: 0.1609\n",
      "Epoch [13/15], Batch [200/507], Loss: 0.3084\n",
      "Epoch [13/15], Batch [300/507], Loss: 0.2338\n",
      "Epoch [13/15], Batch [400/507], Loss: 0.0846\n",
      "Epoch [13/15], Batch [500/507], Loss: 0.3883\n",
      "Test Accuracy: 70.59%\n",
      "Epoch [14/15], Batch [0/507], Loss: 0.1148\n",
      "Epoch [14/15], Batch [100/507], Loss: 0.0522\n",
      "Epoch [14/15], Batch [200/507], Loss: 0.2141\n",
      "Epoch [14/15], Batch [300/507], Loss: 0.1767\n",
      "Epoch [14/15], Batch [400/507], Loss: 0.0973\n",
      "Epoch [14/15], Batch [500/507], Loss: 0.1375\n",
      "Test Accuracy: 69.64%\n",
      "Epoch [15/15], Batch [0/507], Loss: 0.1169\n",
      "Epoch [15/15], Batch [100/507], Loss: 0.0751\n",
      "Epoch [15/15], Batch [200/507], Loss: 0.0365\n",
      "Epoch [15/15], Batch [300/507], Loss: 0.1400\n",
      "Epoch [15/15], Batch [400/507], Loss: 0.1122\n",
      "Epoch [15/15], Batch [500/507], Loss: 0.0942\n",
      "Test Accuracy: 69.71%\n",
      "Epoch [16/15], Batch [0/507], Loss: 0.1085\n",
      "Epoch [16/15], Batch [100/507], Loss: 0.0310\n",
      "Epoch [16/15], Batch [200/507], Loss: 0.0178\n",
      "Epoch [16/15], Batch [300/507], Loss: 0.3932\n",
      "Epoch [16/15], Batch [400/507], Loss: 0.0772\n",
      "Epoch [16/15], Batch [500/507], Loss: 0.0453\n",
      "Test Accuracy: 69.27%\n",
      "Epoch [17/15], Batch [0/507], Loss: 0.0579\n",
      "Epoch [17/15], Batch [100/507], Loss: 0.1083\n",
      "Epoch [17/15], Batch [200/507], Loss: 0.0520\n",
      "Epoch [17/15], Batch [300/507], Loss: 0.0455\n",
      "Epoch [17/15], Batch [400/507], Loss: 0.0150\n",
      "Epoch [17/15], Batch [500/507], Loss: 0.0449\n",
      "Test Accuracy: 69.52%\n",
      "Epoch [18/15], Batch [0/507], Loss: 0.0228\n",
      "Epoch [18/15], Batch [100/507], Loss: 0.0926\n",
      "Epoch [18/15], Batch [200/507], Loss: 0.0646\n",
      "Epoch [18/15], Batch [300/507], Loss: 0.0357\n",
      "Epoch [18/15], Batch [400/507], Loss: 0.0719\n",
      "Epoch [18/15], Batch [500/507], Loss: 0.0262\n",
      "Test Accuracy: 68.39%\n",
      "Epoch [19/15], Batch [0/507], Loss: 0.0102\n",
      "Epoch [19/15], Batch [100/507], Loss: 0.1018\n",
      "Epoch [19/15], Batch [200/507], Loss: 0.0133\n",
      "Epoch [19/15], Batch [300/507], Loss: 0.0327\n",
      "Epoch [19/15], Batch [400/507], Loss: 0.0371\n",
      "Epoch [19/15], Batch [500/507], Loss: 0.0402\n",
      "Test Accuracy: 68.83%\n",
      "Epoch [20/15], Batch [0/507], Loss: 0.0659\n",
      "Epoch [20/15], Batch [100/507], Loss: 0.0266\n",
      "Epoch [20/15], Batch [200/507], Loss: 0.0115\n",
      "Epoch [20/15], Batch [300/507], Loss: 0.0166\n",
      "Epoch [20/15], Batch [400/507], Loss: 0.0625\n",
      "Epoch [20/15], Batch [500/507], Loss: 0.0462\n",
      "Test Accuracy: 70.15%\n",
      "Модель создана\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the neural network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 8 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 32 * 8 * 8)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Define the dataset and data loader\n",
    "train_folder = 'D:/Курсовой проект/train'\n",
    "test_folder =  'D:/Курсовой проект/test'\n",
    "transform = transforms.Compose([transforms.Resize((32,32)),transforms.ToTensor()])\n",
    "train_dataset = datasets.ImageFolder(train_folder, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_folder, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Instantiate the neural network and define the loss function and optimizer\n",
    "model = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# print(torch.__version__)\n",
    "\n",
    "# Train the neural network\n",
    "for epoch in range(20):\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print training progress\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{15}], Batch [{batch_idx}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    # Evaluate the neural network on the test set\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data, targets in test_loader:\n",
    "            scores = model(data)\n",
    "            _, predicted = torch.max(scores.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "torch.save(model.state_dict(), 'person_detection_model.pth')\n",
    "print('Модель создана')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Batch [0/507], Loss: 0.6982\n",
      "Epoch [1/15], Batch [100/507], Loss: 0.7770\n",
      "Epoch [1/15], Batch [200/507], Loss: 0.6781\n",
      "Epoch [1/15], Batch [300/507], Loss: 0.4952\n",
      "Epoch [1/15], Batch [400/507], Loss: 0.5029\n",
      "Epoch [1/15], Batch [500/507], Loss: 0.4651\n",
      "Test Accuracy: 65.78%\n",
      "Epoch [2/15], Batch [0/507], Loss: 0.6343\n",
      "Epoch [2/15], Batch [100/507], Loss: 0.3066\n",
      "Epoch [2/15], Batch [200/507], Loss: 0.4285\n",
      "Epoch [2/15], Batch [300/507], Loss: 0.4703\n",
      "Epoch [2/15], Batch [400/507], Loss: 0.6113\n",
      "Epoch [2/15], Batch [500/507], Loss: 0.5117\n",
      "Test Accuracy: 65.22%\n",
      "Epoch [3/15], Batch [0/507], Loss: 0.4915\n",
      "Epoch [3/15], Batch [100/507], Loss: 0.4295\n",
      "Epoch [3/15], Batch [200/507], Loss: 0.4703\n",
      "Epoch [3/15], Batch [300/507], Loss: 0.5786\n",
      "Epoch [3/15], Batch [400/507], Loss: 0.4021\n",
      "Epoch [3/15], Batch [500/507], Loss: 0.4815\n",
      "Test Accuracy: 67.83%\n",
      "Epoch [4/15], Batch [0/507], Loss: 0.4415\n",
      "Epoch [4/15], Batch [100/507], Loss: 0.3642\n",
      "Epoch [4/15], Batch [200/507], Loss: 0.5346\n",
      "Epoch [4/15], Batch [300/507], Loss: 0.5059\n",
      "Epoch [4/15], Batch [400/507], Loss: 0.4532\n",
      "Epoch [4/15], Batch [500/507], Loss: 0.4102\n",
      "Test Accuracy: 70.03%\n",
      "Epoch [5/15], Batch [0/507], Loss: 0.4750\n",
      "Epoch [5/15], Batch [100/507], Loss: 0.3626\n",
      "Epoch [5/15], Batch [200/507], Loss: 0.3134\n",
      "Epoch [5/15], Batch [300/507], Loss: 0.3901\n",
      "Epoch [5/15], Batch [400/507], Loss: 0.3386\n",
      "Epoch [5/15], Batch [500/507], Loss: 0.3324\n",
      "Test Accuracy: 69.35%\n",
      "Epoch [6/15], Batch [0/507], Loss: 0.3701\n",
      "Epoch [6/15], Batch [100/507], Loss: 0.3521\n",
      "Epoch [6/15], Batch [200/507], Loss: 0.4742\n",
      "Epoch [6/15], Batch [300/507], Loss: 0.4140\n",
      "Epoch [6/15], Batch [400/507], Loss: 0.3182\n",
      "Epoch [6/15], Batch [500/507], Loss: 0.4090\n",
      "Test Accuracy: 70.22%\n",
      "Epoch [7/15], Batch [0/507], Loss: 0.3795\n",
      "Epoch [7/15], Batch [100/507], Loss: 0.2889\n",
      "Epoch [7/15], Batch [200/507], Loss: 0.2595\n",
      "Epoch [7/15], Batch [300/507], Loss: 0.4079\n",
      "Epoch [7/15], Batch [400/507], Loss: 0.3103\n",
      "Epoch [7/15], Batch [500/507], Loss: 0.2713\n",
      "Test Accuracy: 69.35%\n",
      "Epoch [8/15], Batch [0/507], Loss: 0.3585\n",
      "Epoch [8/15], Batch [100/507], Loss: 0.3661\n",
      "Epoch [8/15], Batch [200/507], Loss: 0.4002\n",
      "Epoch [8/15], Batch [300/507], Loss: 0.3272\n",
      "Epoch [8/15], Batch [400/507], Loss: 0.2975\n",
      "Epoch [8/15], Batch [500/507], Loss: 0.2798\n",
      "Test Accuracy: 70.69%\n",
      "Epoch [9/15], Batch [0/507], Loss: 0.3430\n",
      "Epoch [9/15], Batch [100/507], Loss: 0.6466\n",
      "Epoch [9/15], Batch [200/507], Loss: 0.2547\n",
      "Epoch [9/15], Batch [300/507], Loss: 0.1600\n",
      "Epoch [9/15], Batch [400/507], Loss: 0.3997\n",
      "Epoch [9/15], Batch [500/507], Loss: 0.2637\n",
      "Test Accuracy: 70.47%\n",
      "Epoch [10/15], Batch [0/507], Loss: 0.3316\n",
      "Epoch [10/15], Batch [100/507], Loss: 0.4142\n",
      "Epoch [10/15], Batch [200/507], Loss: 0.2872\n",
      "Epoch [10/15], Batch [300/507], Loss: 0.1049\n",
      "Epoch [10/15], Batch [400/507], Loss: 0.2212\n",
      "Epoch [10/15], Batch [500/507], Loss: 0.2044\n",
      "Test Accuracy: 70.44%\n",
      "Epoch [11/15], Batch [0/507], Loss: 0.1943\n",
      "Epoch [11/15], Batch [100/507], Loss: 0.2748\n",
      "Epoch [11/15], Batch [200/507], Loss: 0.2973\n",
      "Epoch [11/15], Batch [300/507], Loss: 0.2715\n",
      "Epoch [11/15], Batch [400/507], Loss: 0.4110\n",
      "Epoch [11/15], Batch [500/507], Loss: 0.2043\n",
      "Test Accuracy: 69.27%\n",
      "Epoch [12/15], Batch [0/507], Loss: 0.1807\n",
      "Epoch [12/15], Batch [100/507], Loss: 0.2165\n",
      "Epoch [12/15], Batch [200/507], Loss: 0.2016\n",
      "Epoch [12/15], Batch [300/507], Loss: 0.1882\n",
      "Epoch [12/15], Batch [400/507], Loss: 0.1498\n",
      "Epoch [12/15], Batch [500/507], Loss: 0.1440\n",
      "Test Accuracy: 70.91%\n",
      "Epoch [13/15], Batch [0/507], Loss: 0.1136\n",
      "Epoch [13/15], Batch [100/507], Loss: 0.1609\n",
      "Epoch [13/15], Batch [200/507], Loss: 0.3084\n",
      "Epoch [13/15], Batch [300/507], Loss: 0.2338\n",
      "Epoch [13/15], Batch [400/507], Loss: 0.0846\n",
      "Epoch [13/15], Batch [500/507], Loss: 0.3883\n",
      "Test Accuracy: 70.59%\n",
      "Epoch [14/15], Batch [0/507], Loss: 0.1148\n",
      "Epoch [14/15], Batch [100/507], Loss: 0.0522\n",
      "Epoch [14/15], Batch [200/507], Loss: 0.2141\n",
      "Epoch [14/15], Batch [300/507], Loss: 0.1767\n",
      "Epoch [14/15], Batch [400/507], Loss: 0.0973\n",
      "Epoch [14/15], Batch [500/507], Loss: 0.1375\n",
      "Test Accuracy: 69.64%\n",
      "Epoch [15/15], Batch [0/507], Loss: 0.1169\n",
      "Epoch [15/15], Batch [100/507], Loss: 0.0751\n",
      "Epoch [15/15], Batch [200/507], Loss: 0.0365\n",
      "Epoch [15/15], Batch [300/507], Loss: 0.1400\n",
      "Epoch [15/15], Batch [400/507], Loss: 0.1122\n",
      "Epoch [15/15], Batch [500/507], Loss: 0.0942\n",
      "Test Accuracy: 69.71%\n",
      "Epoch [16/15], Batch [0/507], Loss: 0.1085\n",
      "Epoch [16/15], Batch [100/507], Loss: 0.0310\n",
      "Epoch [16/15], Batch [200/507], Loss: 0.0178\n",
      "Epoch [16/15], Batch [300/507], Loss: 0.3932\n",
      "Epoch [16/15], Batch [400/507], Loss: 0.0772\n",
      "Epoch [16/15], Batch [500/507], Loss: 0.0453\n",
      "Test Accuracy: 69.27%\n",
      "Epoch [17/15], Batch [0/507], Loss: 0.0579\n",
      "Epoch [17/15], Batch [100/507], Loss: 0.1083\n",
      "Epoch [17/15], Batch [200/507], Loss: 0.0520\n",
      "Epoch [17/15], Batch [300/507], Loss: 0.0455\n",
      "Epoch [17/15], Batch [400/507], Loss: 0.0150\n",
      "Epoch [17/15], Batch [500/507], Loss: 0.0449\n",
      "Test Accuracy: 69.52%\n",
      "Epoch [18/15], Batch [0/507], Loss: 0.0228\n",
      "Epoch [18/15], Batch [100/507], Loss: 0.0926\n",
      "Epoch [18/15], Batch [200/507], Loss: 0.0646\n",
      "Epoch [18/15], Batch [300/507], Loss: 0.0357\n",
      "Epoch [18/15], Batch [400/507], Loss: 0.0719\n",
      "Epoch [18/15], Batch [500/507], Loss: 0.0262\n",
      "Test Accuracy: 68.39%\n",
      "Epoch [19/15], Batch [0/507], Loss: 0.0102\n",
      "Epoch [19/15], Batch [100/507], Loss: 0.1018\n",
      "Epoch [19/15], Batch [200/507], Loss: 0.0133\n",
      "Epoch [19/15], Batch [300/507], Loss: 0.0327\n",
      "Epoch [19/15], Batch [400/507], Loss: 0.0371\n",
      "Epoch [19/15], Batch [500/507], Loss: 0.0402\n",
      "Test Accuracy: 68.83%\n",
      "Epoch [20/15], Batch [0/507], Loss: 0.0659\n",
      "Epoch [20/15], Batch [100/507], Loss: 0.0266\n",
      "Epoch [20/15], Batch [200/507], Loss: 0.0115\n",
      "Epoch [20/15], Batch [300/507], Loss: 0.0166\n",
      "Epoch [20/15], Batch [400/507], Loss: 0.0625\n",
      "Epoch [20/15], Batch [500/507], Loss: 0.0462\n",
      "Test Accuracy: 70.15%\n",
      "Модель создана\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the neural network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 8 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 32 * 8 * 8)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Define the dataset and data loader\n",
    "train_folder = 'D:/Курсовой проект/train'\n",
    "test_folder =  'D:/Курсовой проект/test'\n",
    "transform = transforms.Compose([transforms.Resize((32,32)),transforms.ToTensor()])\n",
    "train_dataset = datasets.ImageFolder(train_folder, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_folder, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Instantiate the neural network and define the loss function and optimizer\n",
    "model = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# print(torch.__version__)\n",
    "\n",
    "# Train the neural network\n",
    "for epoch in range(20):\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print training progress\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{15}], Batch [{batch_idx}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    # Evaluate the neural network on the test set\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data, targets in test_loader:\n",
    "            scores = model(data)\n",
    "            _, predicted = torch.max(scores.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "torch.save(model.state_dict(), 'person_detection_model.pth')\n",
    "print('Модель создана')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Batch [0/507], Loss: 0.6955\n",
      "Epoch [1/15], Batch [100/507], Loss: 0.5711\n",
      "Epoch [1/15], Batch [200/507], Loss: 0.7107\n",
      "Epoch [1/15], Batch [300/507], Loss: 0.5901\n",
      "Epoch [1/15], Batch [400/507], Loss: 0.6160\n",
      "Epoch [1/15], Batch [500/507], Loss: 0.5357\n",
      "Test Accuracy: 65.53%\n",
      "Epoch [2/15], Batch [0/507], Loss: 0.4942\n",
      "Epoch [2/15], Batch [100/507], Loss: 0.6836\n",
      "Epoch [2/15], Batch [200/507], Loss: 0.2942\n",
      "Epoch [2/15], Batch [300/507], Loss: 0.3697\n",
      "Epoch [2/15], Batch [400/507], Loss: 0.3378\n",
      "Epoch [2/15], Batch [500/507], Loss: 0.4719\n",
      "Test Accuracy: 67.59%\n",
      "Epoch [3/15], Batch [0/507], Loss: 0.6343\n",
      "Epoch [3/15], Batch [100/507], Loss: 0.3786\n",
      "Epoch [3/15], Batch [200/507], Loss: 0.4462\n",
      "Epoch [3/15], Batch [300/507], Loss: 0.3974\n",
      "Epoch [3/15], Batch [400/507], Loss: 0.3743\n",
      "Epoch [3/15], Batch [500/507], Loss: 0.4895\n",
      "Test Accuracy: 67.49%\n",
      "Epoch [4/15], Batch [0/507], Loss: 0.3600\n",
      "Epoch [4/15], Batch [100/507], Loss: 0.3731\n",
      "Epoch [4/15], Batch [200/507], Loss: 0.3857\n",
      "Epoch [4/15], Batch [300/507], Loss: 0.4449\n",
      "Epoch [4/15], Batch [400/507], Loss: 0.4265\n",
      "Epoch [4/15], Batch [500/507], Loss: 0.4590\n",
      "Test Accuracy: 68.95%\n",
      "Epoch [5/15], Batch [0/507], Loss: 0.3352\n",
      "Epoch [5/15], Batch [100/507], Loss: 0.2763\n",
      "Epoch [5/15], Batch [200/507], Loss: 0.3666\n",
      "Epoch [5/15], Batch [300/507], Loss: 0.3101\n",
      "Epoch [5/15], Batch [400/507], Loss: 0.4598\n",
      "Epoch [5/15], Batch [500/507], Loss: 0.3281\n",
      "Test Accuracy: 69.08%\n",
      "Epoch [6/15], Batch [0/507], Loss: 0.3939\n",
      "Epoch [6/15], Batch [100/507], Loss: 0.5302\n",
      "Epoch [6/15], Batch [200/507], Loss: 0.4140\n",
      "Epoch [6/15], Batch [300/507], Loss: 0.3423\n",
      "Epoch [6/15], Batch [400/507], Loss: 0.2305\n",
      "Epoch [6/15], Batch [500/507], Loss: 0.5038\n",
      "Test Accuracy: 69.00%\n",
      "Epoch [7/15], Batch [0/507], Loss: 0.3005\n",
      "Epoch [7/15], Batch [100/507], Loss: 0.4106\n",
      "Epoch [7/15], Batch [200/507], Loss: 0.2623\n",
      "Epoch [7/15], Batch [300/507], Loss: 0.2196\n",
      "Epoch [7/15], Batch [400/507], Loss: 0.2779\n",
      "Epoch [7/15], Batch [500/507], Loss: 0.4674\n",
      "Test Accuracy: 70.66%\n",
      "Epoch [8/15], Batch [0/507], Loss: 0.4160\n",
      "Epoch [8/15], Batch [100/507], Loss: 0.2084\n",
      "Epoch [8/15], Batch [200/507], Loss: 0.3570\n",
      "Epoch [8/15], Batch [300/507], Loss: 0.4136\n",
      "Epoch [8/15], Batch [400/507], Loss: 0.1746\n",
      "Epoch [8/15], Batch [500/507], Loss: 0.2651\n",
      "Test Accuracy: 69.54%\n",
      "Epoch [9/15], Batch [0/507], Loss: 0.3469\n",
      "Epoch [9/15], Batch [100/507], Loss: 0.3260\n",
      "Epoch [9/15], Batch [200/507], Loss: 0.2611\n",
      "Epoch [9/15], Batch [300/507], Loss: 0.2332\n",
      "Epoch [9/15], Batch [400/507], Loss: 0.2034\n",
      "Epoch [9/15], Batch [500/507], Loss: 0.3913\n",
      "Test Accuracy: 70.03%\n",
      "Epoch [10/15], Batch [0/507], Loss: 0.1732\n",
      "Epoch [10/15], Batch [100/507], Loss: 0.4006\n",
      "Epoch [10/15], Batch [200/507], Loss: 0.2824\n",
      "Epoch [10/15], Batch [300/507], Loss: 0.1996\n",
      "Epoch [10/15], Batch [400/507], Loss: 0.2612\n",
      "Epoch [10/15], Batch [500/507], Loss: 0.1900\n",
      "Test Accuracy: 68.64%\n",
      "Epoch [11/15], Batch [0/507], Loss: 0.2387\n",
      "Epoch [11/15], Batch [100/507], Loss: 0.2764\n",
      "Epoch [11/15], Batch [200/507], Loss: 0.1533\n",
      "Epoch [11/15], Batch [300/507], Loss: 0.1677\n",
      "Epoch [11/15], Batch [400/507], Loss: 0.1859\n",
      "Epoch [11/15], Batch [500/507], Loss: 0.2058\n",
      "Test Accuracy: 68.73%\n",
      "Epoch [12/15], Batch [0/507], Loss: 0.1704\n",
      "Epoch [12/15], Batch [100/507], Loss: 0.3570\n",
      "Epoch [12/15], Batch [200/507], Loss: 0.2404\n",
      "Epoch [12/15], Batch [300/507], Loss: 0.2788\n",
      "Epoch [12/15], Batch [400/507], Loss: 0.1360\n",
      "Epoch [12/15], Batch [500/507], Loss: 0.1573\n",
      "Test Accuracy: 69.37%\n",
      "Epoch [13/15], Batch [0/507], Loss: 0.1242\n",
      "Epoch [13/15], Batch [100/507], Loss: 0.0854\n",
      "Epoch [13/15], Batch [200/507], Loss: 0.2990\n",
      "Epoch [13/15], Batch [300/507], Loss: 0.1343\n",
      "Epoch [13/15], Batch [400/507], Loss: 0.1454\n",
      "Epoch [13/15], Batch [500/507], Loss: 0.3379\n",
      "Test Accuracy: 69.39%\n",
      "Epoch [14/15], Batch [0/507], Loss: 0.1010\n",
      "Epoch [14/15], Batch [100/507], Loss: 0.0908\n",
      "Epoch [14/15], Batch [200/507], Loss: 0.3356\n",
      "Epoch [14/15], Batch [300/507], Loss: 0.1886\n",
      "Epoch [14/15], Batch [400/507], Loss: 0.2101\n",
      "Epoch [14/15], Batch [500/507], Loss: 0.2468\n",
      "Test Accuracy: 69.35%\n",
      "Epoch [15/15], Batch [0/507], Loss: 0.0503\n",
      "Epoch [15/15], Batch [100/507], Loss: 0.2246\n",
      "Epoch [15/15], Batch [200/507], Loss: 0.1416\n",
      "Epoch [15/15], Batch [300/507], Loss: 0.0969\n",
      "Epoch [15/15], Batch [400/507], Loss: 0.0394\n",
      "Epoch [15/15], Batch [500/507], Loss: 0.0909\n",
      "Test Accuracy: 69.10%\n",
      "Epoch [16/15], Batch [0/507], Loss: 0.1026\n",
      "Epoch [16/15], Batch [100/507], Loss: 0.1095\n",
      "Epoch [16/15], Batch [200/507], Loss: 0.1518\n",
      "Epoch [16/15], Batch [300/507], Loss: 0.0819\n",
      "Epoch [16/15], Batch [400/507], Loss: 0.0511\n",
      "Epoch [16/15], Batch [500/507], Loss: 0.0830\n",
      "Test Accuracy: 69.91%\n",
      "Epoch [17/15], Batch [0/507], Loss: 0.0501\n",
      "Epoch [17/15], Batch [100/507], Loss: 0.0292\n",
      "Epoch [17/15], Batch [200/507], Loss: 0.0193\n",
      "Epoch [17/15], Batch [300/507], Loss: 0.0298\n",
      "Epoch [17/15], Batch [400/507], Loss: 0.0127\n",
      "Epoch [17/15], Batch [500/507], Loss: 0.0694\n",
      "Test Accuracy: 69.74%\n",
      "Epoch [18/15], Batch [0/507], Loss: 0.0765\n",
      "Epoch [18/15], Batch [100/507], Loss: 0.0680\n",
      "Epoch [18/15], Batch [200/507], Loss: 0.0246\n",
      "Epoch [18/15], Batch [300/507], Loss: 0.0180\n",
      "Epoch [18/15], Batch [400/507], Loss: 0.0317\n",
      "Epoch [18/15], Batch [500/507], Loss: 0.0218\n",
      "Test Accuracy: 69.32%\n",
      "Epoch [19/15], Batch [0/507], Loss: 0.0400\n",
      "Epoch [19/15], Batch [100/507], Loss: 0.0145\n",
      "Epoch [19/15], Batch [200/507], Loss: 0.0340\n",
      "Epoch [19/15], Batch [300/507], Loss: 0.0123\n",
      "Epoch [19/15], Batch [400/507], Loss: 0.1198\n",
      "Epoch [19/15], Batch [500/507], Loss: 0.0508\n",
      "Test Accuracy: 68.83%\n",
      "Epoch [20/15], Batch [0/507], Loss: 0.0844\n",
      "Epoch [20/15], Batch [100/507], Loss: 0.0207\n",
      "Epoch [20/15], Batch [200/507], Loss: 0.0122\n",
      "Epoch [20/15], Batch [300/507], Loss: 0.0542\n",
      "Epoch [20/15], Batch [400/507], Loss: 0.0196\n",
      "Epoch [20/15], Batch [500/507], Loss: 0.0428\n",
      "Test Accuracy: 68.66%\n",
      "Epoch [21/15], Batch [0/507], Loss: 0.0220\n",
      "Epoch [21/15], Batch [100/507], Loss: 0.0243\n",
      "Epoch [21/15], Batch [200/507], Loss: 0.0057\n",
      "Epoch [21/15], Batch [300/507], Loss: 0.0030\n",
      "Epoch [21/15], Batch [400/507], Loss: 0.0036\n",
      "Epoch [21/15], Batch [500/507], Loss: 0.0263\n",
      "Test Accuracy: 69.10%\n",
      "Epoch [22/15], Batch [0/507], Loss: 0.0303\n",
      "Epoch [22/15], Batch [100/507], Loss: 0.0034\n",
      "Epoch [22/15], Batch [200/507], Loss: 0.0106\n",
      "Epoch [22/15], Batch [300/507], Loss: 0.0443\n",
      "Epoch [22/15], Batch [400/507], Loss: 0.0147\n",
      "Epoch [22/15], Batch [500/507], Loss: 0.0093\n",
      "Test Accuracy: 68.32%\n",
      "Epoch [23/15], Batch [0/507], Loss: 0.0344\n",
      "Epoch [23/15], Batch [100/507], Loss: 0.0199\n",
      "Epoch [23/15], Batch [200/507], Loss: 0.0178\n",
      "Epoch [23/15], Batch [300/507], Loss: 0.0247\n",
      "Epoch [23/15], Batch [400/507], Loss: 0.0191\n",
      "Epoch [23/15], Batch [500/507], Loss: 0.0408\n",
      "Test Accuracy: 68.44%\n",
      "Epoch [24/15], Batch [0/507], Loss: 0.0064\n",
      "Epoch [24/15], Batch [100/507], Loss: 0.0091\n",
      "Epoch [24/15], Batch [200/507], Loss: 0.0066\n",
      "Epoch [24/15], Batch [300/507], Loss: 0.0235\n",
      "Epoch [24/15], Batch [400/507], Loss: 0.0249\n",
      "Epoch [24/15], Batch [500/507], Loss: 0.0224\n",
      "Test Accuracy: 67.71%\n",
      "Epoch [25/15], Batch [0/507], Loss: 0.0931\n",
      "Epoch [25/15], Batch [100/507], Loss: 0.0088\n",
      "Epoch [25/15], Batch [200/507], Loss: 0.0112\n",
      "Epoch [25/15], Batch [300/507], Loss: 0.0263\n",
      "Epoch [25/15], Batch [400/507], Loss: 0.0687\n",
      "Epoch [25/15], Batch [500/507], Loss: 0.0032\n",
      "Test Accuracy: 68.10%\n",
      "Epoch [26/15], Batch [0/507], Loss: 0.0024\n",
      "Epoch [26/15], Batch [100/507], Loss: 0.0988\n",
      "Epoch [26/15], Batch [200/507], Loss: 0.0051\n",
      "Epoch [26/15], Batch [300/507], Loss: 0.0018\n",
      "Epoch [26/15], Batch [400/507], Loss: 0.0300\n",
      "Epoch [26/15], Batch [500/507], Loss: 0.0514\n",
      "Test Accuracy: 69.00%\n",
      "Epoch [27/15], Batch [0/507], Loss: 0.0257\n",
      "Epoch [27/15], Batch [100/507], Loss: 0.0101\n",
      "Epoch [27/15], Batch [200/507], Loss: 0.0157\n",
      "Epoch [27/15], Batch [300/507], Loss: 0.0053\n",
      "Epoch [27/15], Batch [400/507], Loss: 0.0193\n",
      "Epoch [27/15], Batch [500/507], Loss: 0.0004\n",
      "Test Accuracy: 69.35%\n",
      "Epoch [28/15], Batch [0/507], Loss: 0.0129\n",
      "Epoch [28/15], Batch [100/507], Loss: 0.0056\n",
      "Epoch [28/15], Batch [200/507], Loss: 0.0007\n",
      "Epoch [28/15], Batch [300/507], Loss: 0.0005\n",
      "Epoch [28/15], Batch [400/507], Loss: 0.0023\n",
      "Epoch [28/15], Batch [500/507], Loss: 0.0012\n",
      "Test Accuracy: 69.44%\n",
      "Epoch [29/15], Batch [0/507], Loss: 0.0006\n",
      "Epoch [29/15], Batch [100/507], Loss: 0.0008\n",
      "Epoch [29/15], Batch [200/507], Loss: 0.0011\n",
      "Epoch [29/15], Batch [300/507], Loss: 0.0019\n",
      "Epoch [29/15], Batch [400/507], Loss: 0.0030\n",
      "Epoch [29/15], Batch [500/507], Loss: 0.0390\n",
      "Test Accuracy: 66.95%\n",
      "Epoch [30/15], Batch [0/507], Loss: 0.0838\n",
      "Epoch [30/15], Batch [100/507], Loss: 0.0088\n",
      "Epoch [30/15], Batch [200/507], Loss: 0.0299\n",
      "Epoch [30/15], Batch [300/507], Loss: 0.0083\n",
      "Epoch [30/15], Batch [400/507], Loss: 0.0167\n",
      "Epoch [30/15], Batch [500/507], Loss: 0.0593\n",
      "Test Accuracy: 69.49%\n",
      "Epoch [31/15], Batch [0/507], Loss: 0.0515\n",
      "Epoch [31/15], Batch [100/507], Loss: 0.0020\n",
      "Epoch [31/15], Batch [200/507], Loss: 0.0180\n",
      "Epoch [31/15], Batch [300/507], Loss: 0.0007\n",
      "Epoch [31/15], Batch [400/507], Loss: 0.0048\n",
      "Epoch [31/15], Batch [500/507], Loss: 0.0025\n",
      "Test Accuracy: 69.35%\n",
      "Epoch [32/15], Batch [0/507], Loss: 0.0016\n",
      "Epoch [32/15], Batch [100/507], Loss: 0.0013\n",
      "Epoch [32/15], Batch [200/507], Loss: 0.0128\n",
      "Epoch [32/15], Batch [300/507], Loss: 0.0023\n",
      "Epoch [32/15], Batch [400/507], Loss: 0.0130\n",
      "Epoch [32/15], Batch [500/507], Loss: 0.0420\n",
      "Test Accuracy: 67.66%\n",
      "Epoch [33/15], Batch [0/507], Loss: 0.1371\n",
      "Epoch [33/15], Batch [100/507], Loss: 0.0040\n",
      "Epoch [33/15], Batch [200/507], Loss: 0.0028\n",
      "Epoch [33/15], Batch [300/507], Loss: 0.0010\n",
      "Epoch [33/15], Batch [400/507], Loss: 0.0046\n",
      "Epoch [33/15], Batch [500/507], Loss: 0.0051\n",
      "Test Accuracy: 68.32%\n",
      "Epoch [34/15], Batch [0/507], Loss: 0.0014\n",
      "Epoch [34/15], Batch [100/507], Loss: 0.0017\n",
      "Epoch [34/15], Batch [200/507], Loss: 0.0025\n",
      "Epoch [34/15], Batch [300/507], Loss: 0.0004\n",
      "Epoch [34/15], Batch [400/507], Loss: 0.0126\n",
      "Epoch [34/15], Batch [500/507], Loss: 0.0322\n",
      "Test Accuracy: 68.30%\n",
      "Epoch [35/15], Batch [0/507], Loss: 0.0074\n",
      "Epoch [35/15], Batch [100/507], Loss: 0.0043\n",
      "Epoch [35/15], Batch [200/507], Loss: 0.0064\n",
      "Epoch [35/15], Batch [300/507], Loss: 0.0028\n",
      "Epoch [35/15], Batch [400/507], Loss: 0.0371\n",
      "Epoch [35/15], Batch [500/507], Loss: 0.0056\n",
      "Test Accuracy: 69.20%\n",
      "Epoch [36/15], Batch [0/507], Loss: 0.0059\n",
      "Epoch [36/15], Batch [100/507], Loss: 0.0004\n",
      "Epoch [36/15], Batch [200/507], Loss: 0.0001\n",
      "Epoch [36/15], Batch [300/507], Loss: 0.0003\n",
      "Epoch [36/15], Batch [400/507], Loss: 0.1116\n",
      "Epoch [36/15], Batch [500/507], Loss: 0.0061\n",
      "Test Accuracy: 67.42%\n",
      "Epoch [37/15], Batch [0/507], Loss: 0.0176\n",
      "Epoch [37/15], Batch [100/507], Loss: 0.0079\n",
      "Epoch [37/15], Batch [200/507], Loss: 0.0133\n",
      "Epoch [37/15], Batch [300/507], Loss: 0.0040\n",
      "Epoch [37/15], Batch [400/507], Loss: 0.0059\n",
      "Epoch [37/15], Batch [500/507], Loss: 0.0321\n",
      "Test Accuracy: 69.13%\n",
      "Epoch [38/15], Batch [0/507], Loss: 0.0057\n",
      "Epoch [38/15], Batch [100/507], Loss: 0.0012\n",
      "Epoch [38/15], Batch [200/507], Loss: 0.0006\n",
      "Epoch [38/15], Batch [300/507], Loss: 0.0012\n",
      "Epoch [38/15], Batch [400/507], Loss: 0.0052\n",
      "Epoch [38/15], Batch [500/507], Loss: 0.0181\n",
      "Test Accuracy: 69.27%\n",
      "Epoch [39/15], Batch [0/507], Loss: 0.0752\n",
      "Epoch [39/15], Batch [100/507], Loss: 0.0005\n",
      "Epoch [39/15], Batch [200/507], Loss: 0.0022\n",
      "Epoch [39/15], Batch [300/507], Loss: 0.0808\n",
      "Epoch [39/15], Batch [400/507], Loss: 0.1048\n",
      "Epoch [39/15], Batch [500/507], Loss: 0.0018\n",
      "Test Accuracy: 68.61%\n",
      "Epoch [40/15], Batch [0/507], Loss: 0.0002\n",
      "Epoch [40/15], Batch [100/507], Loss: 0.0011\n",
      "Epoch [40/15], Batch [200/507], Loss: 0.0022\n",
      "Epoch [40/15], Batch [300/507], Loss: 0.0144\n",
      "Epoch [40/15], Batch [400/507], Loss: 0.0898\n",
      "Epoch [40/15], Batch [500/507], Loss: 0.0008\n",
      "Test Accuracy: 69.05%\n",
      "Модель создана\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the neural network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 8 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 32 * 8 * 8)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Define the dataset and data loader\n",
    "train_folder = 'D:/Курсовой проект/train'\n",
    "test_folder =  'D:/Курсовой проект/test'\n",
    "transform = transforms.Compose([transforms.Resize((32,32)),transforms.ToTensor()])\n",
    "train_dataset = datasets.ImageFolder(train_folder, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_folder, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Instantiate the neural network and define the loss function and optimizer\n",
    "model = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# print(torch.__version__)\n",
    "\n",
    "# Train the neural network\n",
    "for epoch in range(40):\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print training progress\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{15}], Batch [{batch_idx}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    # Evaluate the neural network on the test set\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data, targets in test_loader:\n",
    "            scores = model(data)\n",
    "            _, predicted = torch.max(scores.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "torch.save(model.state_dict(), 'person_detection_model.pth')\n",
    "print('Модель создана')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
