{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Загрузка и предобработка данных\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(root='path/to/train/dataset', transform=transform)\n",
    "test_data = datasets.ImageFolder(root='path/to/test/dataset', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "\n",
    "# Определение архитектуры нейронной сети\n",
    "class CustomNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(32 * 56 * 56, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 2)  # 2 класса: человек или не человек\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Создание модели и определение функции потерь и оптимизатора\n",
    "model = CustomNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Обучение модели\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Вычисление точности на тестовом наборе данных\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Сохранение обученной модели\n",
    "torch.save(model.state_dict(), 'custom_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Batch [0/1207], Loss: 0.6910\n",
      "Epoch [1/20], Batch [100/1207], Loss: 0.6778\n",
      "Epoch [1/20], Batch [200/1207], Loss: 0.6873\n",
      "Epoch [1/20], Batch [300/1207], Loss: 0.6858\n",
      "Epoch [1/20], Batch [400/1207], Loss: 0.6609\n",
      "Epoch [1/20], Batch [500/1207], Loss: 0.6899\n",
      "Epoch [1/20], Batch [600/1207], Loss: 0.6778\n",
      "Epoch [1/20], Batch [700/1207], Loss: 0.6840\n",
      "Epoch [1/20], Batch [800/1207], Loss: 0.6195\n",
      "Epoch [1/20], Batch [900/1207], Loss: 0.6673\n",
      "Epoch [1/20], Batch [1000/1207], Loss: 0.6445\n",
      "Epoch [1/20], Batch [1100/1207], Loss: 0.7070\n",
      "Epoch [1/20], Batch [1200/1207], Loss: 0.6392\n",
      "Test Accuracy: 59.97%\n",
      "Epoch [2/20], Batch [0/1207], Loss: 0.7069\n",
      "Epoch [2/20], Batch [100/1207], Loss: 0.5554\n",
      "Epoch [2/20], Batch [200/1207], Loss: 0.6229\n",
      "Epoch [2/20], Batch [300/1207], Loss: 0.6411\n",
      "Epoch [2/20], Batch [400/1207], Loss: 0.6469\n",
      "Epoch [2/20], Batch [500/1207], Loss: 0.6278\n",
      "Epoch [2/20], Batch [600/1207], Loss: 0.6701\n",
      "Epoch [2/20], Batch [700/1207], Loss: 0.7111\n",
      "Epoch [2/20], Batch [800/1207], Loss: 0.6965\n",
      "Epoch [2/20], Batch [900/1207], Loss: 0.6095\n",
      "Epoch [2/20], Batch [1000/1207], Loss: 0.6564\n",
      "Epoch [2/20], Batch [1100/1207], Loss: 0.5712\n",
      "Epoch [2/20], Batch [1200/1207], Loss: 0.5561\n",
      "Test Accuracy: 62.51%\n",
      "Epoch [3/20], Batch [0/1207], Loss: 0.7066\n",
      "Epoch [3/20], Batch [100/1207], Loss: 0.6066\n",
      "Epoch [3/20], Batch [200/1207], Loss: 0.6448\n",
      "Epoch [3/20], Batch [300/1207], Loss: 0.5550\n",
      "Epoch [3/20], Batch [400/1207], Loss: 0.7141\n",
      "Epoch [3/20], Batch [500/1207], Loss: 0.6883\n",
      "Epoch [3/20], Batch [600/1207], Loss: 0.6833\n",
      "Epoch [3/20], Batch [700/1207], Loss: 0.6500\n",
      "Epoch [3/20], Batch [800/1207], Loss: 0.6474\n",
      "Epoch [3/20], Batch [900/1207], Loss: 0.5282\n",
      "Epoch [3/20], Batch [1000/1207], Loss: 0.5944\n",
      "Epoch [3/20], Batch [1100/1207], Loss: 0.6888\n",
      "Epoch [3/20], Batch [1200/1207], Loss: 0.6337\n",
      "Test Accuracy: 63.25%\n",
      "Epoch [4/20], Batch [0/1207], Loss: 0.6606\n",
      "Epoch [4/20], Batch [100/1207], Loss: 0.6314\n",
      "Epoch [4/20], Batch [200/1207], Loss: 0.6252\n",
      "Epoch [4/20], Batch [300/1207], Loss: 0.7053\n",
      "Epoch [4/20], Batch [400/1207], Loss: 0.7113\n",
      "Epoch [4/20], Batch [500/1207], Loss: 0.6397\n",
      "Epoch [4/20], Batch [600/1207], Loss: 0.6657\n",
      "Epoch [4/20], Batch [700/1207], Loss: 0.7120\n",
      "Epoch [4/20], Batch [800/1207], Loss: 0.6873\n",
      "Epoch [4/20], Batch [900/1207], Loss: 0.6057\n",
      "Epoch [4/20], Batch [1000/1207], Loss: 0.6618\n",
      "Epoch [4/20], Batch [1100/1207], Loss: 0.6726\n",
      "Epoch [4/20], Batch [1200/1207], Loss: 0.7130\n",
      "Test Accuracy: 58.59%\n",
      "Epoch [5/20], Batch [0/1207], Loss: 0.5440\n",
      "Epoch [5/20], Batch [100/1207], Loss: 0.5926\n",
      "Epoch [5/20], Batch [200/1207], Loss: 0.7000\n",
      "Epoch [5/20], Batch [300/1207], Loss: 0.6011\n",
      "Epoch [5/20], Batch [400/1207], Loss: 0.5437\n",
      "Epoch [5/20], Batch [500/1207], Loss: 0.7374\n",
      "Epoch [5/20], Batch [600/1207], Loss: 0.6720\n",
      "Epoch [5/20], Batch [700/1207], Loss: 0.7281\n",
      "Epoch [5/20], Batch [800/1207], Loss: 0.6664\n",
      "Epoch [5/20], Batch [900/1207], Loss: 0.6655\n",
      "Epoch [5/20], Batch [1000/1207], Loss: 0.6572\n",
      "Epoch [5/20], Batch [1100/1207], Loss: 0.6547\n",
      "Epoch [5/20], Batch [1200/1207], Loss: 0.6099\n",
      "Test Accuracy: 62.18%\n",
      "Epoch [6/20], Batch [0/1207], Loss: 0.6878\n",
      "Epoch [6/20], Batch [100/1207], Loss: 0.6856\n",
      "Epoch [6/20], Batch [200/1207], Loss: 0.6431\n",
      "Epoch [6/20], Batch [300/1207], Loss: 0.6044\n",
      "Epoch [6/20], Batch [400/1207], Loss: 0.5801\n",
      "Epoch [6/20], Batch [500/1207], Loss: 0.6385\n",
      "Epoch [6/20], Batch [600/1207], Loss: 0.6386\n",
      "Epoch [6/20], Batch [700/1207], Loss: 0.7647\n",
      "Epoch [6/20], Batch [800/1207], Loss: 0.5791\n",
      "Epoch [6/20], Batch [900/1207], Loss: 0.5959\n",
      "Epoch [6/20], Batch [1000/1207], Loss: 0.6205\n",
      "Epoch [6/20], Batch [1100/1207], Loss: 0.6245\n",
      "Epoch [6/20], Batch [1200/1207], Loss: 0.6782\n",
      "Test Accuracy: 64.18%\n",
      "Epoch [7/20], Batch [0/1207], Loss: 0.5741\n",
      "Epoch [7/20], Batch [100/1207], Loss: 0.5716\n",
      "Epoch [7/20], Batch [200/1207], Loss: 0.6612\n",
      "Epoch [7/20], Batch [300/1207], Loss: 0.5265\n",
      "Epoch [7/20], Batch [400/1207], Loss: 0.5978\n",
      "Epoch [7/20], Batch [500/1207], Loss: 0.5139\n",
      "Epoch [7/20], Batch [600/1207], Loss: 0.5346\n",
      "Epoch [7/20], Batch [700/1207], Loss: 0.5827\n",
      "Epoch [7/20], Batch [800/1207], Loss: 0.6745\n",
      "Epoch [7/20], Batch [900/1207], Loss: 0.5794\n",
      "Epoch [7/20], Batch [1000/1207], Loss: 0.6658\n",
      "Epoch [7/20], Batch [1100/1207], Loss: 0.6791\n",
      "Epoch [7/20], Batch [1200/1207], Loss: 0.5402\n",
      "Test Accuracy: 62.10%\n",
      "Epoch [8/20], Batch [0/1207], Loss: 0.5193\n",
      "Epoch [8/20], Batch [100/1207], Loss: 0.5135\n",
      "Epoch [8/20], Batch [200/1207], Loss: 0.5964\n",
      "Epoch [8/20], Batch [300/1207], Loss: 0.6331\n",
      "Epoch [8/20], Batch [400/1207], Loss: 0.4920\n",
      "Epoch [8/20], Batch [500/1207], Loss: 0.4279\n",
      "Epoch [8/20], Batch [600/1207], Loss: 0.4914\n",
      "Epoch [8/20], Batch [700/1207], Loss: 0.4934\n",
      "Epoch [8/20], Batch [800/1207], Loss: 0.6253\n",
      "Epoch [8/20], Batch [900/1207], Loss: 0.6501\n",
      "Epoch [8/20], Batch [1000/1207], Loss: 0.5640\n",
      "Epoch [8/20], Batch [1100/1207], Loss: 0.6104\n",
      "Epoch [8/20], Batch [1200/1207], Loss: 0.5400\n",
      "Test Accuracy: 62.59%\n",
      "Epoch [9/20], Batch [0/1207], Loss: 0.5571\n",
      "Epoch [9/20], Batch [100/1207], Loss: 0.4289\n",
      "Epoch [9/20], Batch [200/1207], Loss: 0.3959\n",
      "Epoch [9/20], Batch [300/1207], Loss: 0.5382\n",
      "Epoch [9/20], Batch [400/1207], Loss: 0.4360\n",
      "Epoch [9/20], Batch [500/1207], Loss: 0.4709\n",
      "Epoch [9/20], Batch [600/1207], Loss: 0.4946\n",
      "Epoch [9/20], Batch [700/1207], Loss: 0.6105\n",
      "Epoch [9/20], Batch [800/1207], Loss: 0.4627\n",
      "Epoch [9/20], Batch [900/1207], Loss: 0.5796\n",
      "Epoch [9/20], Batch [1000/1207], Loss: 0.5610\n",
      "Epoch [9/20], Batch [1100/1207], Loss: 0.6615\n",
      "Epoch [9/20], Batch [1200/1207], Loss: 0.4376\n",
      "Test Accuracy: 61.33%\n",
      "Epoch [10/20], Batch [0/1207], Loss: 0.5360\n",
      "Epoch [10/20], Batch [100/1207], Loss: 0.4477\n",
      "Epoch [10/20], Batch [200/1207], Loss: 0.3510\n",
      "Epoch [10/20], Batch [300/1207], Loss: 0.4631\n",
      "Epoch [10/20], Batch [400/1207], Loss: 0.5352\n",
      "Epoch [10/20], Batch [500/1207], Loss: 0.5395\n",
      "Epoch [10/20], Batch [600/1207], Loss: 0.4743\n",
      "Epoch [10/20], Batch [700/1207], Loss: 0.6259\n",
      "Epoch [10/20], Batch [800/1207], Loss: 0.6840\n",
      "Epoch [10/20], Batch [900/1207], Loss: 0.6315\n",
      "Epoch [10/20], Batch [1000/1207], Loss: 0.6258\n",
      "Epoch [10/20], Batch [1100/1207], Loss: 0.5136\n",
      "Epoch [10/20], Batch [1200/1207], Loss: 0.3983\n",
      "Test Accuracy: 61.66%\n",
      "Epoch [11/20], Batch [0/1207], Loss: 0.3561\n",
      "Epoch [11/20], Batch [100/1207], Loss: 0.5233\n",
      "Epoch [11/20], Batch [200/1207], Loss: 0.2314\n",
      "Epoch [11/20], Batch [300/1207], Loss: 0.3288\n",
      "Epoch [11/20], Batch [400/1207], Loss: 0.3115\n",
      "Epoch [11/20], Batch [500/1207], Loss: 0.3548\n",
      "Epoch [11/20], Batch [600/1207], Loss: 0.4535\n",
      "Epoch [11/20], Batch [700/1207], Loss: 0.3853\n",
      "Epoch [11/20], Batch [800/1207], Loss: 0.4897\n",
      "Epoch [11/20], Batch [900/1207], Loss: 0.5519\n",
      "Epoch [11/20], Batch [1000/1207], Loss: 0.3131\n",
      "Epoch [11/20], Batch [1100/1207], Loss: 0.4726\n",
      "Epoch [11/20], Batch [1200/1207], Loss: 0.4212\n",
      "Test Accuracy: 59.23%\n",
      "Epoch [12/20], Batch [0/1207], Loss: 0.2939\n",
      "Epoch [12/20], Batch [100/1207], Loss: 0.4286\n",
      "Epoch [12/20], Batch [200/1207], Loss: 0.2971\n",
      "Epoch [12/20], Batch [300/1207], Loss: 0.2338\n",
      "Epoch [12/20], Batch [400/1207], Loss: 0.1969\n",
      "Epoch [12/20], Batch [500/1207], Loss: 0.3564\n",
      "Epoch [12/20], Batch [600/1207], Loss: 0.1787\n",
      "Epoch [12/20], Batch [700/1207], Loss: 0.2875\n",
      "Epoch [12/20], Batch [800/1207], Loss: 0.4943\n",
      "Epoch [12/20], Batch [900/1207], Loss: 0.3997\n",
      "Epoch [12/20], Batch [1000/1207], Loss: 0.3418\n",
      "Epoch [12/20], Batch [1100/1207], Loss: 0.4270\n",
      "Epoch [12/20], Batch [1200/1207], Loss: 0.4517\n",
      "Test Accuracy: 59.10%\n",
      "Epoch [13/20], Batch [0/1207], Loss: 0.3034\n",
      "Epoch [13/20], Batch [100/1207], Loss: 0.4651\n",
      "Epoch [13/20], Batch [200/1207], Loss: 0.1948\n",
      "Epoch [13/20], Batch [300/1207], Loss: 0.3110\n",
      "Epoch [13/20], Batch [400/1207], Loss: 0.2336\n",
      "Epoch [13/20], Batch [500/1207], Loss: 0.2692\n",
      "Epoch [13/20], Batch [600/1207], Loss: 0.2112\n",
      "Epoch [13/20], Batch [700/1207], Loss: 0.3219\n",
      "Epoch [13/20], Batch [800/1207], Loss: 0.4509\n",
      "Epoch [13/20], Batch [900/1207], Loss: 0.2718\n",
      "Epoch [13/20], Batch [1000/1207], Loss: 0.4511\n",
      "Epoch [13/20], Batch [1100/1207], Loss: 0.3473\n",
      "Epoch [13/20], Batch [1200/1207], Loss: 0.2497\n",
      "Test Accuracy: 58.27%\n",
      "Epoch [14/20], Batch [0/1207], Loss: 0.2248\n",
      "Epoch [14/20], Batch [100/1207], Loss: 0.1304\n",
      "Epoch [14/20], Batch [200/1207], Loss: 0.2051\n",
      "Epoch [14/20], Batch [300/1207], Loss: 0.2679\n",
      "Epoch [14/20], Batch [400/1207], Loss: 0.1574\n",
      "Epoch [14/20], Batch [500/1207], Loss: 0.1471\n",
      "Epoch [14/20], Batch [600/1207], Loss: 0.3362\n",
      "Epoch [14/20], Batch [700/1207], Loss: 0.2336\n",
      "Epoch [14/20], Batch [800/1207], Loss: 0.2366\n",
      "Epoch [14/20], Batch [900/1207], Loss: 0.1958\n",
      "Epoch [14/20], Batch [1000/1207], Loss: 0.1997\n",
      "Epoch [14/20], Batch [1100/1207], Loss: 0.4720\n",
      "Epoch [14/20], Batch [1200/1207], Loss: 0.2286\n",
      "Test Accuracy: 59.00%\n",
      "Epoch [15/20], Batch [0/1207], Loss: 0.0642\n",
      "Epoch [15/20], Batch [100/1207], Loss: 0.0601\n",
      "Epoch [15/20], Batch [200/1207], Loss: 0.1430\n",
      "Epoch [15/20], Batch [300/1207], Loss: 0.1261\n",
      "Epoch [15/20], Batch [400/1207], Loss: 0.2605\n",
      "Epoch [15/20], Batch [500/1207], Loss: 0.2955\n",
      "Epoch [15/20], Batch [600/1207], Loss: 0.1710\n",
      "Epoch [15/20], Batch [700/1207], Loss: 0.2042\n",
      "Epoch [15/20], Batch [800/1207], Loss: 0.1771\n",
      "Epoch [15/20], Batch [900/1207], Loss: 0.1771\n",
      "Epoch [15/20], Batch [1000/1207], Loss: 0.1817\n",
      "Epoch [15/20], Batch [1100/1207], Loss: 0.1260\n",
      "Epoch [15/20], Batch [1200/1207], Loss: 0.2401\n",
      "Test Accuracy: 57.66%\n",
      "Epoch [16/20], Batch [0/1207], Loss: 0.1417\n",
      "Epoch [16/20], Batch [100/1207], Loss: 0.0719\n",
      "Epoch [16/20], Batch [200/1207], Loss: 0.2115\n",
      "Epoch [16/20], Batch [300/1207], Loss: 0.0605\n",
      "Epoch [16/20], Batch [400/1207], Loss: 0.0655\n",
      "Epoch [16/20], Batch [500/1207], Loss: 0.0826\n",
      "Epoch [16/20], Batch [600/1207], Loss: 0.0544\n",
      "Epoch [16/20], Batch [700/1207], Loss: 0.2683\n",
      "Epoch [16/20], Batch [800/1207], Loss: 0.0947\n",
      "Epoch [16/20], Batch [900/1207], Loss: 0.0813\n",
      "Epoch [16/20], Batch [1000/1207], Loss: 0.0544\n",
      "Epoch [16/20], Batch [1100/1207], Loss: 0.3405\n",
      "Epoch [16/20], Batch [1200/1207], Loss: 0.2547\n",
      "Test Accuracy: 58.42%\n",
      "Epoch [17/20], Batch [0/1207], Loss: 0.0941\n",
      "Epoch [17/20], Batch [100/1207], Loss: 0.0949\n",
      "Epoch [17/20], Batch [200/1207], Loss: 0.0251\n",
      "Epoch [17/20], Batch [300/1207], Loss: 0.0465\n",
      "Epoch [17/20], Batch [400/1207], Loss: 0.0536\n",
      "Epoch [17/20], Batch [500/1207], Loss: 0.0625\n",
      "Epoch [17/20], Batch [600/1207], Loss: 0.0803\n",
      "Epoch [17/20], Batch [700/1207], Loss: 0.0730\n",
      "Epoch [17/20], Batch [800/1207], Loss: 0.3129\n",
      "Epoch [17/20], Batch [900/1207], Loss: 0.0674\n",
      "Epoch [17/20], Batch [1000/1207], Loss: 0.0530\n",
      "Epoch [17/20], Batch [1100/1207], Loss: 0.0992\n",
      "Epoch [17/20], Batch [1200/1207], Loss: 0.1232\n",
      "Test Accuracy: 58.77%\n",
      "Epoch [18/20], Batch [0/1207], Loss: 0.1102\n",
      "Epoch [18/20], Batch [100/1207], Loss: 0.0389\n",
      "Epoch [18/20], Batch [200/1207], Loss: 0.0521\n",
      "Epoch [18/20], Batch [300/1207], Loss: 0.0995\n",
      "Epoch [18/20], Batch [400/1207], Loss: 0.0244\n",
      "Epoch [18/20], Batch [500/1207], Loss: 0.0485\n",
      "Epoch [18/20], Batch [600/1207], Loss: 0.0982\n",
      "Epoch [18/20], Batch [700/1207], Loss: 0.0749\n",
      "Epoch [18/20], Batch [800/1207], Loss: 0.1430\n",
      "Epoch [18/20], Batch [900/1207], Loss: 0.1115\n",
      "Epoch [18/20], Batch [1000/1207], Loss: 0.2895\n",
      "Epoch [18/20], Batch [1100/1207], Loss: 0.0689\n",
      "Epoch [18/20], Batch [1200/1207], Loss: 0.2869\n",
      "Test Accuracy: 57.69%\n",
      "Epoch [19/20], Batch [0/1207], Loss: 0.0895\n",
      "Epoch [19/20], Batch [100/1207], Loss: 0.0331\n",
      "Epoch [19/20], Batch [200/1207], Loss: 0.0104\n",
      "Epoch [19/20], Batch [300/1207], Loss: 0.0469\n",
      "Epoch [19/20], Batch [400/1207], Loss: 0.0449\n",
      "Epoch [19/20], Batch [500/1207], Loss: 0.0498\n",
      "Epoch [19/20], Batch [600/1207], Loss: 0.1536\n",
      "Epoch [19/20], Batch [700/1207], Loss: 0.0220\n",
      "Epoch [19/20], Batch [800/1207], Loss: 0.1053\n",
      "Epoch [19/20], Batch [900/1207], Loss: 0.0359\n",
      "Epoch [19/20], Batch [1000/1207], Loss: 0.0417\n",
      "Epoch [19/20], Batch [1100/1207], Loss: 0.0274\n",
      "Epoch [19/20], Batch [1200/1207], Loss: 0.1644\n",
      "Test Accuracy: 57.36%\n",
      "Epoch [20/20], Batch [0/1207], Loss: 0.0501\n",
      "Epoch [20/20], Batch [100/1207], Loss: 0.0864\n",
      "Epoch [20/20], Batch [200/1207], Loss: 0.0487\n",
      "Epoch [20/20], Batch [300/1207], Loss: 0.0469\n",
      "Epoch [20/20], Batch [400/1207], Loss: 0.0496\n",
      "Epoch [20/20], Batch [500/1207], Loss: 0.1150\n",
      "Epoch [20/20], Batch [600/1207], Loss: 0.1189\n",
      "Epoch [20/20], Batch [700/1207], Loss: 0.0330\n",
      "Epoch [20/20], Batch [800/1207], Loss: 0.0429\n",
      "Epoch [20/20], Batch [900/1207], Loss: 0.1398\n",
      "Epoch [20/20], Batch [1000/1207], Loss: 0.0571\n",
      "Epoch [20/20], Batch [1100/1207], Loss: 0.1266\n",
      "Epoch [20/20], Batch [1200/1207], Loss: 0.1384\n",
      "Test Accuracy: 57.43%\n",
      "Модель создана\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the neural network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 8 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 32 * 8 * 8)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Define the dataset and data loader\n",
    "train_folder = 'D:/Курсовой проект/Diploma project (Дилом)/Data/Train'\n",
    "test_folder =  'D:/Курсовой проект/Diploma project (Дилом)/Data/Test'\n",
    "transform = transforms.Compose([transforms.Resize((32,32)),transforms.ToTensor()])\n",
    "train_dataset = datasets.ImageFolder(train_folder, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_folder, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Instantiate the neural network and define the loss function and optimizer\n",
    "model = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# print(torch.__version__)\n",
    "\n",
    "# Train the neural network\n",
    "for epoch in range(20):\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print training progress\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{20}], Batch [{batch_idx}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    # Evaluate the neural network on the test set\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data, targets in test_loader:\n",
    "            scores = model(data)\n",
    "            _, predicted = torch.max(scores.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "torch.save(model.state_dict(), 'person_detection_model.pth')\n",
    "print('Модель создана')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
